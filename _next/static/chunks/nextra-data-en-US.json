{"/":{"title":"Introduction","data":{"":"안녕하세요 :) 이 곳은 MySQL 의 기본적인 내용들을 정리하는 페이지입니다.개인적으로 오래 전에 여기 저기에 정리해둔 문서들을 보면서 정신이 산만해져서 하나의 페이지에 모아두면 좋겠다고 생각해서 개설했고, 가급적 빠른 시일 내에 정리되도록 노력중입니다."}},"/about":{"title":"About","data":{"":"This is the about page! This page is shown on the navbar."}},"/mysql-index":{"title":"Mysql Index","data":{"인덱스#인덱스":"예를 들어 아래와 같은 데이터가 있습니다. 문자 C 를 찾으려면 끝까지 모두 읽어야 합니다.\nD\tZ\tB\tA\tK\tC\t\n이번에는 위의 데이터를 오름차순으로 정렬했습니다. 정렬된 표에서는 C 가 3번째에 있다는 사실이 확실하기에 더 빠르게 읽어올 수 있습니다.\nA\tB\tC\tD\tK\tZ","인덱스를-사용하는-이유#인덱스를 사용하는 이유":"무작위로 데이터의 위치를 O(N)으로 탐색하기 보다는 이렇게 정렬된 자료구조를 통해 데이터를 접근한다면 데이터를 탐색해야 하는 범위가 축소되기에 데이터의 접근 속도가 월등히 빨라지게 됩니다. 즉, 인덱스를 사용하는 이유는 '인덱스의 탐색 범위'를 줄여서 접근 속도를 최적화하기 위해서입니다.","인덱스-자료구조의-원리#인덱스 자료구조의 원리":"인덱스는 하나의 자료구조입니다. 데이터의 주소들을 특정 순서로 기억하고 있는 하나의 목차와 같은 역할을 합니다. 예를 들어 아래와 같은 테이블이 있습니다.\n데이터 주소\tTicker\t회사명\t시가총액\t1\tMSFT\tMicrosoft\t3.049 T\t2\tNVDA\tNvdia\t1.97 T\t3\tAAPL\tApple\t2.818 T\t\n만약 위의 데이터를 시가총액이 가장 낮은 회사를 찾는다거나 시가 총액이 가장 높은 회사를 찾는 다거나 하는 조회를 하려면 아래와 같은 자료구조를 미리 만들어두면 조회 성능상에 이점이 생깁니다.\n시가총액\t데이터 주소\t1.97 T\t2\t2.818 T\t3\t3.049 T\t1\t\n만약 시가총액이 가장 낮은 회사를 찾아야 할 경우 가장 맨 처음에 나타난 1.97T 에 대한 데이터는 데이터 주소가 2 이고 데이터 주소 2 에 대한 원본 데이터를 확인해보면 NVDA 인 것을 확인 가능합니다.만약 시가총액이 가장 높은 회사를 찾아야 한다면 가장 마지막에서 첫번째 데이터를 읽으면 되고, 3.049 T 에 대해 데이터 주소가 1인데 데이터 주소 1에 대한 원본데이터를 확인해서 MSFT 라는 것을 확인 가능합니다.","b-tree---인덱스의-자료구조#B+ Tree - 인덱스의 자료구조":"","btree-학습자료#B+Tree 학습자료":"https://www.cs.usfca.edu/~galles/visualization/BPlusTree.html","여러가지-자료구조들과의-비교#여러가지 자료구조들과의 비교":"List\n정렬되지 않았을 때 : O(n)\n정렬된 리스트에서는 : O(logN)\n정렬되지 않은 리스트의 정렬 시간 복잡도는 : 평균 (Mlog(N))\nArrayList와 같은 구조일 경우 삽입/삭제 시 비용이 높다.\nHashMap\n단건 검색 속도 : O(1)\n범위 탐색 : O(N)\n전방 일치 탐색 불가 (e.g. like 'AB%')\nTree\n트리의 높이에 따라 시간복잡도가 결정된다.\n트리의 높이를 최소화 하는 것이 중요\n한쪽으로 노드가 치우치지 않도록 하는 균형잡힌 트리를 사용\ne.g. Red Black Tree, B+Tree, ...\nRed Black Tree 는 각 노드가 하나의 데이터 역할을 하고, B+Tree 의 각 노드는 리프노드의 주소 역할을 수행","btree#B+Tree":"B+Tree 는 데이터 자체는 하나의 링크드리스트로 구성되어 있고, 이 링크드 리스트는 트리의 리프로 구성되어 있습니다. 그리고 이 데이터의 주소로 구성된 트리를 이진탐색하면서 원하는 위치를 찾기에, 리프노드에 구성된 링크드 리스트에서 원하는 위치를 빠르게 찾아낼 수 있습니다.예를 들면 1~17 까지의 데이터를 추가할 때 위와 같이 B+Tree 가 생성됩니다. 가장 마지막 리프노드에 1~17 데이터가 이어져있고, 각각의 트리는 데이터의 주소를 이진탐색할 수 있도록 구성되어 있음을 확인 가능합니다.데이터가 insert 될 때 어떻게 동작하는지는 https://www.cs.usfca.edu/~galles/visualization/BPlusTree.html 에서 확인 가능합니다.\nB+Tree 는 기본적으로 아래의 성격을 가집니다.\n삽입/삭제 시 항상 균형을 유지\n하나의 노드가 여러개의 자식 노드를 가지는 것 가능\n리프노드에만 데이터가 존재하기에 연속적인 데이터에 접근 시에 장점을 가짐","mysql-의-btree#mysql 의 B+Tree":"mysql의 인덱스는 B+Tree 의 리프노드에 PK를 가지고 있습니다. 참고로 Oracle 에서는 B+Tree 의 리프노드에 데이터의 주소를 가지고 있습니다.이렇게 PK를 B+Tree 의 리프노드에 가지고 있는 것은 PK를 클러스터드 인덱스로 가지고 있기에 용이한 구조임을 유추할 수 있습니다.아래의 그림은 Canada 라는 인덱스 키를 검색할 때 B-Tree 의 주소를 어떻게 검색하는지 절차를 그림으로 그린 것입니다.","클러스터-인덱스#클러스터 인덱스":"MySQL 의 PK 는 클러스터 인덱스로 이루어져 있습니다.MySQL 의 PK가 아닌 일반 인덱스 역시 MySQL의 B+Tree 는 PK기반으로 구성하기에 일반 인덱스 역시 내부적으로는 PK를 가지며 클러스터 인덱스로 구성되어 있습니다.","클러스터-인덱스-장단점#클러스터 인덱스, 장단점":"클러스터 인덱스라는 것은 인덱스가 특정 범위를 두고 모여 있는 인덱스라는 것을 의미합니다. 클러스터 인덱스의 장점은 데이터의 지역성이 이뤄지기 때문에 데이터 조회시 조금 더 빠른 성능을 낼 수 있다는 점입니다. 반면, 데이터가 새로 들어올 때 재조정을 해야 할수도 있기 때문에 클러스터 인덱스가 리빌드 될 때의 오버헤드는 단점이 될 수 있습니다.예를 들어 아래와 같은 데이터가 있다고 해보겠습니다.\n클러스터 인덱스 키\t데이터 주소\t100\tA\t200\tB\t300\tC\t500\tD\t\n이 상황에서 아래와 같이 새로운 데이터인 400 이 들어오는 경우에는 500 에 해당하는 클러스터 인덱스 키에 대한 데이터 주소는 재배치 됩니다.\n클러스터 인덱스 키\t데이터 주소\t100\tA\t200\tB\t300\tC\t400 (새로들어옴)\tD\t500\tE\t\n이렇게 적은 데이터에서는 조금만 이동되었지만, 데이터가 많아지면 재배치할 데이터들이 많아지게 됩니다.","인덱스-역시-pk로-이뤄져-있으며-클러스터-인덱스로-구성#인덱스 역시 PK로 이뤄져 있으며 클러스터 인덱스로 구성":"MySQL 의 PK가 아닌 일반 인덱스 역시 MySQL의 B+Tree 는 PK기반으로 구성하기에 일반 인덱스 역시 내부적으로는 PK를 가지며 클러스터 인덱스로 구성되어 있습니다.","커버링-인덱스#커버링 인덱스":"커버링 인덱스는 데이터가 담긴 테이블을 직접 접근하지 않고도 인덱스로만 원하는 데이터에 접근할 수 있도록 구성한 인덱스를 의미합니다.예를 들어 아래와 같은 데이터가 있다고 해보겠습니다.\nid(PK)\tticker\tmarket_cap\t1\tAAPL\t2.818\t2\tMETA\t1.234\t3\tMSFT\t3.049\t4\tNVDA\t1.97\t\n그리고 시가총액인 market_cap 에 대한 인덱스가 아래와 같이 구성되어 있다고 해보겠습니다.\nmarket_cap\tid(PK)\t1.234\t2\t1.97\t4\t2.818\t1\t3.049\t3\t\n이 때 아래와 같은 SQL은 테이블을 탐색하지 않고도 인덱스만으로도 원하는 데이터를 인출해올 수 있습니다.\nSELECT market_cap\r\nFROM stock_symbols\r\nWHERE market_cap > 2;\n아래의 SQL 역시 원본 테이블을 탐색하지 않고도 인덱스만으로도 원하는 데이터를 인출해올 수 있습니다.\nSELECT id, market_cap\r\nFROM stock_symbols\r\nWHERE market_cap > 2;\n그런데 이때 Ticker 데이터 역시 가져와야 하는 상황이 있습니다. 이런 경우에는 아래와 같은 SQL 을  사용한다면 커버링 인덱스를 거치게 되어서 데이터를 필요한 데이터만 접근해서 조회해오기에 효율적으로 조회할 수 있습니다.\nSELECT A.id, A.ticker, A.market_cap\r\nFROM stock_symbols A\r\nINNER JOIN (\r\n    SELECT id, market_cap\r\n    FROM stock_symbols\r\n    WHERE market_cap > 2\r\n) B\r\n ON A.id = B.id\n커버링 인덱스를 사용하게 되면 order by, offset, limit 등을 사용하는 것으로 인한 불필요한 데이터 블록에 대한 접근을 커버링 인덱스를 이용해서 최소화할 수 있게 됩니다.","인덱스-사용-시-주의해야-하는-점들#인덱스 사용 시 주의해야 하는 점들":"인덱스 사용 시 주의해야 할 점은 아래와 같습니다\n인덱스 필드 가공은 피하는 것이 좋다\n복합인덱스 사용시에는 복합된 컬럼을 모두 사용해야만 인덱스를 조회하게 된다\n기본적으로 하나의 쿼리는 하나의 인덱스만 탄다\nSQL에 대해서 인덱스가 동작하지 않는 경우가 있을 수 있기 때문에, 성능이 중요한 쿼리일 경우 explain 을 통해서 확인하는 습관을 들이는 것을 추천합니다. 또한 무작정 인덱스를 사용한다고 해서 항상 성능이 향상된다는 고정관념 역시 탈피해야 하고 무분별한 인덱스 추가작업 인지 역시 충분히 고민을 해봐야 합니다. 인덱스를 사용하면 조회속도에 이점을 얻을 수는 있지만, 새로운 데이터 추가 시에 데이터베이스 내부적으로는 커버링 인덱스, B+Tree 의 데이터 위치들을 재정렬하는 등의 작업들이 일어납니다. 너무 과도한 인덱스 사용보다는 꼭 필요한 필드를 인덱스로 선택해서 사용하는 것을 권장합니다.흔히 인덱스를 사용하는 것에 대해 쓰기를 희생하고 조회를 얻는 것 이라는 이야기를 합니다. 이 말을 떠올려서 꼭 필요한 곳에 인덱스를 사용하도록 고민을 해봐야 할 것 같습니다.","인덱스-필드-가공은-피하는-것이-좋다#인덱스 필드 가공은 피하는 것이 좋다":"인덱스 필드를 가공하면 인덱스를 타지 못하게 됩니다.예를 들어 아래의 테이블이 있다고 하겠습니다. market_cap 필드는 biginteger 타입으로 선언되어 있습니다.\nid(PK)\tticker\tmarket_cap (indexed)\t1\tAAPL\t2.818\t2\tMETA\t1.234\t3\tMSFT\t3.049\t4\tNVDA\t1.97\t\n그리고 아래의 쿼리는 인덱스를 타지 못합니다. 자료형이 다르기 때문입니다. 이렇게 자료형이 다른 경우 옵티마이저는 내부적으로  to string 처리를 하게 되어서 인덱스를 통한 검색이 이뤄지지 않습니다.\nSELECT * \r\nFROM stock_symbols\r\nWHERE market_cap = '2.818'\n아래의 쿼리 역시 인덱스를 타지 못합니다. 인덱스 필드를 가공하고 있기 때문입니다.\nSELECT * \r\nFROM stock_symbols\r\nWHERE market_cap*100 = 2.818","복합인덱스-사용시에는-복합된-컬럼을-모두-사용해야만-인덱스를-조회하게-된다#복합인덱스 사용시에는 복합된 컬럼을 모두 사용해야만 인덱스를 조회하게 된다":"예를 들어 아래와 같은 테이블이 있다고 해보겠습니다. 복합 인덱스로 ticker, marekt_cap 기반의 복합인덱스를 구성했습니다.\nid(PK)\tticker(indexed a1)\tmarket_cap (indexed a2)\tceo\t1\tAAPL\t2.818\tTim Cook\t2\tMETA\t1.234\tMark Zuckerberg\t3\tMSFT\t3.049\tSatya Nadella\t4\tNVDA\t1.97\tJen-Hsun Huang\t\n이 경우 인덱스는 아래와 같이 구성됩니다.\nid(PK)\tticker(indexed a1)\tmarket_cap (indexed a2)\t1\tAAPL\t2.818\t2\tMETA\t1.234\t3\tMSFT\t3.049\t4\tNVDA\t1.97\t\n복합인덱스 조합은 { ticker, market_cap } 조합에 대해서 ticker 에 대해 먼저 정렬된 행에 대해서 market_cap 에 대해 정렬한 결과를 인덱스로 가지고 있는데, 만약 아래의 쿼리를 수행한다면 아래의 쿼리는 인덱스를 거치지 못하게 됩니다.\nSELECT id, ticker, market_cap\r\nFROM stock_symbols\r\nWHERE market_cap > 1;\n왜냐하면 market_cap 은 복합 키 내에 보조적인 역할을 할 뿐이기에 market_cap > 1 처럼 market_cap 필드 하나에 대해서만 위치를 조회하는 것은 전혀 인덱스를 거치지 못합니다.","기본적으로-하나의-쿼리는-하나의-인덱스만-탄다#기본적으로 하나의 쿼리는 하나의 인덱스만 탄다":"하나의 쿼리는 하나의 인덱스만 탑니다. 여러 인덱스 테이블을 동시에 탐색하는 것은 기본적으로는 불가능하며, index merge hint 를 사용한다면 가능하기는 합니다. 따라서 where , order by , group by 를 사용하는 쿼리에서는 인덱스를 잘 고려해야 합니다."}},"/query-cache":{"title":"Query Cache","data":{"쿼리-캐시#쿼리 캐시":"","쿼리-캐시란#쿼리 캐시란":"쿼리캐시에 SQL 과 데이터를 매핑해서 가지고 있다가 똑같은 SQL이 왔을때 캐시에 보관해둔 결과물을 응답하도록 캐시에 SQL의 결과를 보관하고 있는 것을 의미합니다.쿼리 캐시는 데이터를 캐시하기 때문에 테이블의 데이터가 변경되면 캐시의 데이터도 함께 업데이트해줘야 합니다. 이런 업데이트 작업으로 인해 락(Lock) 이슈가 있었고 이런 이슈는 이익보다는 단점도 크고 캐시 데이터 관리에 대한 비용(성능상의 단점)이 컸기에 8.0 이후로는 MySQL 에서 쿼리 캐시 기능은 폐기 되었습니다.다른 데이터베이스에도 쿼리 캐시와 유사한 기능이 있습니다. 오라클에서도 쿼리캐시와 비슷한 기능을 소프트 캐시 라는 이름으로 제공하기는 하지만, MySQL 처럼 SQL에 대한  데이터 까지는 매핑하지는 않고 실행 계획 까지만 캐싱을 합니다. 즉, 오라클은 MySQL 과 쿼리 캐시가 다르며 실행 계획까지만 제공한다는 점에서 MySQL과는 차이가 있습니다.","mysql-50--mysql-80#MySQL 5.0 → MySQL 8.0":"MySQL 5.0 까지는 쿼리 캐시 기능이 있었지만, MySQL 8.0 부터는 쿼리 캐시 기능이 폐기되었습니다.테이블의 데이터가 변경되면, 쿼리캐시에도 똑같이 변경된 내용을 반영해야 하는데 이 과정에서 락과 같은 이슈가 있었고 쿼리 캐시로 인해 이점보다는 문제점이 크기에 8.0 이후로는 폐기되었습니다.","참고-오라클--소프트파싱-하드파싱#참고) 오라클 : 소프트파싱, 하드파싱":"오라클에는 소프트파싱, 하드파싱이라는 개념이 있습니다.\r\n소프트파싱, 하드 파싱의 개념은 아래와 같습니다.소프트파싱\n실행 계획을 캐시에서 찾아서 옵티마이저 과정 생략 후 실행단계로 넘어갑니다.\n실행 계획 까지만 캐싱이 됩니다.\n하드 파싱\n실행 계획을 캐시에서 찾지 못했을 경우 옵티마이저 과정을 거친 후 실행단계로 넘어갑니다.\n하지만 오라클은 5.0 대의 MySQL 처럼 모든 SQL과 매핑해서 데이터까지 캐싱하지는 않습니다. \n물론 힌트나 설정으로 모든 SQL과 매핑해서 데이터까지 캐싱하는 것이 가능하기는 하지만  오라클에서 기본적으로 제공되는 기능은 아닙니다."}},"/mysql-architecture":{"title":"Mysql Architecture","data":{"mysql-구조#MySQL 구조":"","쿼리파서#쿼리파서":"SQL 을 파싱해서 Syntax Tree 를 만듭니다. 이 과정에서 문법 검사가 이뤄집니다.마치 javascript 의 정적 페이지를 빌드할 때 linting 등의 밸리데이션 작업을 하듯 이 과정에서 문법검사등을 수행합니다. 문법검사가 끝나면 Syntax Tree 를 만듭니다.쿼리 파서가 만들어내는 Syntax Tree 에 대해서는 https://observablehq.com/@john-guerra/sql-query-visualizer에서 자세히 설명하고 있습니다.\nSELECT distinct * FROM A, B WHERE name=\"John\" and age> 32 \r\n\tand name not in (select name  from A where name!= \"John\") \r\n\tGROUP BY name\r\n\tLIMIT 10\n위와 같은 쿼리에 대해서 쿼리 파서는 아래와 같은 Syntax Tree 를 만들어냅니다.","전처리기#전처리기":"쿼리 파서가 만든 Syntax Tree 를 토대로 전처리를 시작합니다. 테이블,컬럼 존재여부, 접근 권한 등과 같은 Semantic 오류를 검사합니다.","옵티마이저#옵티마이저":"불필요한 조건을 제거하고, 테이블 순서, 통계정보를 바탕으로 전략을 결정합니다. 이 과정을 실행계획 수립이라고 합니다. 쿼리를 처리하기 위한 여러 방법들을 만들고 이 방법들에 대한 비용 정보, 테이블의 통계 정보를 이용해 비용을 산정하는 역할을 수행합니다.옵티마이저가 선택하게 되는 전략에 따라 성능이 많이 달라지기도 하는데, 가끔 나쁜 판단이 이뤄질 수도 있어서 개발자가 힌트를 사용하거나 explain 명령을 통해 도움을 주기도 합니다.","쿼리-실행기#쿼리 실행기":"옵티마이저가 선택한 전략을 바탕으로 쿼리를 실행하는데, 이때 쿼리 실행기는 Handler API 라는 것을 사용해 스토리지 엔진에 요청을 수행합니다.","스토리지-엔진#스토리지 엔진":"스토리지 엔진은 데이터를 가져오거나 저장하는 역할을 수행합니다. Handler API 에 맞춰서 플러그인 형태로 직접 구현해서 스토리지 엔진에 접근하는 프로그램을 개발하는 것 역시 가능합니다.MySQL에는 InnoDB, MyIsam 등 여러 종류의 스토리지 엔진이 존재하는데, 8.0 이후 부터는 InnoDB 엔진이 디폴트 스토리지 엔진이 되었고, 많은 사람들이 MySQL 의 스토리지 엔진을 이야기할 때 대부분 InnoDB 엔진을 이야기합니다.InnoDB 엔진은 클러스터 인덱스, Redo-Undo 로그, Buffer pool 등과 같은 특징을 가집니다.클러스터 인덱스는 쉽게 말해 인덱스의 데이터 주소가 가까운 곳이 서로 클러스터 처럼 모여있는 것을 의미하는데 인덱스의 리프노드를 PK로 구성하고 인덱스 역시도 PK기반으로 구성되게끔 해서 커버링 인덱스의 성격을 가지게 되어 데이터가 지역성을 갖추게 되어서 데이터의 조회가 효율적으로 이뤄지게 하는 것을 의미합니다.Redo-Undo 로그 는 MySQL 이 동시성환경에서 MVCC 시에 사용하는 전략을 의미합니다."}},"/memory-disk-wal":{"title":"Memory Disk Wal","data":{"memory-vs-disk-wal#Memory vs Disk, WAL":"데이터베이스는 디스크에 데이터를 기록합니다. 그런데 디스크는 메모리에 비해 I/O 작업 비용이 꽤 큽니다.이런 이유로 데이터베이스는 메모리를 이용해서 메모리 캐시 히트율을 높여서 디스크로의 접근을 최소화합니다.하지만 데이터베이스가 메모리만 사용할 수는 없습니다. 메모리의 가격이 디스크보다 비싸기에 메모리를 방대하게 사용하는 것은 쉽지 않습니다. 또한 메모리는 휘발성을 가진 저장장치이기에 메모리가 off 되었을 때에 대책이 필요합니다.이런 이유로 메모리에 데이터를 쓰기 전에 디스크에 쿼리 기록을 남깁니다. 그리고 디스크에는 랜덤접근보다는 순차접근이 효율적이기에 쿼리 로그는 순차 접근 방식으로 기록되며, 현재 읽고 있는 위치를 기록하게 됩니다. 이렇게 되면 장애 발생시 마지막으로 읽었던 위치의 쿼리 로그와 여러 정보들을 조합해서 메모리와 디스크 사이의 데이터 불일치문제를 해결할 수 있게 됩니다.이번 문서에서는 이 과정에 대해 세부적으로 설명합니다.","메모리-쓰기-시-장애를-보완---wal#메모리 쓰기 시 장애를 보완 - WAL":"데이터베이스의 데이터는 최종적으로 디스크에 저장됩니다. 디스크는 메모리에 비해 성능이 많이 떨어집니다. 따라서 데이터베이스 성능에 있어서 핵심으로 두는 중점사항은 \"디스크로의 랜덤I/O 를 최소화하는 것\" 입니다.디스크 접근에는 순차 I/O 와 랜덤 I/O 가 있습니다. 순차 I/O는 가장 마지막에 읽었던 위치만 알고 있으면 되기에 쓰기 위치를 파악하는데에 있어서 많은 시간이 소요되지 않습니다. 랜덤 I/O 의 경우 원하는 데이터의 위치를 찾은 후 그 위치에 쓰기/수정 작업을 해야 하는데 이때 디스크에 접근하는 비용이 메모리에 접근하는 것에 비해 꽤 큽니다.이런 경우 디스크에 접근하는 횟수를 줄이는 대신 메모리에 캐시 히트율을 높인다면 쓰기에 소요되는 비용이 줄어듭니다. 하지만 이 경우 메모리의 데이터가 유실될 수 있다는 점 역시 고려해야 합니다. 데이터베이스에 장애가 발생하면, 메모리에 있는 내용들은 디스크에 반영되지 않기에 디스크의 내용과 메모리의 내용이 일치하지 않는 상황이 발생할 수 있습니다. 이런 이유로 대부분의 데이터베이스는 이런 경우에 대비해 WAL(Write Ahead Log) 기반으로 동작합니다.\nWAL (Write Ahead Log)\n데이터베이스는 쿼리 수행 전에 어떤 쿼리를 사용하는지 실행하려 했던 쿼리들의 기록을 디스크에 순차기록을 해둡니다. 따라서 장애 등으로 인해 수행되지 않은 쿼리 들은 이 WAL 이라는 곳에서 읽어서 장애를 복구할 때 WAL에 쌓아둔 실행되지 않는 쿼리를 디스크에 반영합니다. 이렇게 해서 유실될 수 있는 쿼리 요청으로 인해 장애 직전 메모리에 남아있었던 결과와 디스크에 기록된 내용들이 달라질 수 있는 문제로 인한 데이터의 싱크가 깨지는 현상을 해결이 가능합니다. 이렇게 실행하려는 쿼리의 기록을 디스크에 순차 기록을 해두어 데이터의 싱크가 깨지는 현상을 방지하는 기술을 WAL(Write Ahead Log) 라고 부릅니다.","저장장치-별-latency#저장장치 별 Latency":"Latency Numbers Every Programmer Should Know\ngist.github.com/jboner/latency.txt"}},"/transaction/intro":{"title":"Intro","data":{"소개#소개":"보통 IoT나 지표데이터 수집, 블로그 같은 경우 격리수준이 높을필요가 없을 수도 있습니다. 하지만 결제,송금,뱅킹,포인트 같은 영역에서는 트랜잭션이 중요합니다.데이터베이스는 데이터를 처리하고 커밋하기 까지의 단위를 트랜잭션 단위로 처리할 수 있도록 합니다. 그리고 이 트랜잭션이라는 기준을 갖추기 위해서는 원자성, 일관성, 격리성, 지속성 이라는 요소를 갖춰야 합니다.쉽게 설명하면 트랜잭션 하나는 하나의 원자적인 단위로 취급되어 트랜잭션 내에서 하나가 실패할 경우 트랜잭션 내부의 모든 연산이 롤백되어야 하는 원자성, 트랜잭션에서 수행하는 연산은 데이터베이스의 무결성 제약 조건이 지켜져야 한다는 일관성, 수행중인 트랜잭션은 다른 트랜잭션에 의해 변경되거나 수정되지 않아야 한다는 격리성, 완료된 트랜잭션은 기록되어야 한다는 지속성 이라는 원칙이 있습니다.이번 카테고리에서는 이런 내용들을 다루며, SQL로는 이렇게 트랜잭션을 열고 닫고, Spring 에서는 어떻게 선언적인 트랜잭션을 사용하는지, 트랜잭션 전파 옵션은 무엇이 있는지를 정리합니다.개인적으로 시간이 부족하기도 하지만, 가급적이면 빠른 시일 내에 정리하도록 하겠습니다."}},"/transaction/transaction-isolation-level":{"title":"Transaction Isolation Level","data":{"트랜잭션-격리수준#트랜잭션 격리수준":"트랜잭션의 격리성을 확보할 때 격리 수준을 4가지 단계로 제공할 수 있습니다. 격리수준이 낮은 수준에서 높은 수준으로 나열해보면 아래와 같습니다.\nRead Uncommitted (커밋되지 않은 읽기) : Dirty Read, Non Repeatable Read, Phantom Read 발생\nRead Committed (커밋된 읽기) : Non Repeatable Read, Phantom Read 발생\nRepeatable Read (반복 가능한 읽기) : Phantom Read 발생\nSerializable (직렬화 가능) : 가장 엄격한 격리수준\n각각의 격리 수준에서 발생하는 나타나는 현상들을 정리하면 아래와 같습니다.\n\tDirty Read\tNon Repeatable Read\tPhantom Read\tRead Unommitted\t발생\t발생\t발생\tRead Committed\t\t발생\t발생\tRepeatable Read\t\t\t발생\tSerializable Read\t\t\t\t\n아래에서부터는 각각의 트랜잭션 격리수준과 발생할 수 있는 현상을 예를 들어 설명합니다.","read-uncommitted#Read Uncommitted":"Dirty Read 가 발생합니다.\n커밋되지 않은 것이라도 읽어들일 수 있는 격리 수준입니다. 트랜잭션에서 커밋하지 않은 수정 중인 내용이 다른 트랜잭션에 의해 읽을 수 있는 격리수준으로 가장 낮은 수준의 격리 수준입니다. 만약 다른 트랜잭션으로부터 읽어들인 데이터가 커밋되지 않은 데이터인데 그 데이터가 롤백된다면 데이터의 정합성에 문제가 생깁니다.","dirty-read-현상#Dirty Read 현상":"트랜잭션 t1 이 데이터를 수정하고 있고 커밋하지 않은 상황에서 트랜잭션 t2 가 t1이 커밋하지 않은 데이터를 읽어들일 수 있는 현상입니다. 만약 트랜잭션 t2가 Dirty Read 한 데이터를 사용하고 있는 중에 t1 이 수정 중인 데이터를 롤백한다면 데이터의 정합성에 문제가 생깁니다.은행 송금을 예로 들면 Read Uncommitted 에서 발생할 수 있는 Dirty Read 현상은 아래와 같은 장애를 일으킬 수 있습니다.","read-committed#Read Committed":"Non Repeatable Read 가 발생합니다.\n다른 트랜잭션에서 커밋된 데이터를 읽어들일 수 있는 격리수준을 의미합니다. 커밋된 데이터를 읽어들이기에 롤백하지 못한 데이터를 읽게 되는 불상사는 없습니다. 하지만 다른 트랜잭션에서 수정 후 커밋을 한 데이터를 읽어들이기에 조회 작업 도중에 다른 트랜잭션에서 같은 데이터에 대한 수정본 커밋을 한다면 수정본이 읽히는 현상인 Non Repeatable Read 현상이 발생합니다.","non-repeatable-read-현상#Non Repeatable Read 현상":"은행 송금을 예로 들면 Read Committed 에서 발생할 수 있는 Non Repeatable Read 현상은 아래와 같은 상황이 발생합니다.","repeatable-read#Repeatable Read":"Phantom Read 가 발생합니다.\nRepeatable Read 격리 수준은 Read Committed 가 보장하지 못하는 수정/커밋 된 데이터에 대해 Repeatable Read 가 가능하도록 하는 격리 수준입니다. Repeatable Read 는 다른 트랜잭션에서 수정/커밋 했어도 한번 조회했던 데이터를 조회하면 그 데이터에 대해서는 같은 데이터가 조회됨을 보장합니다.하지만 새롭게 추가된 데이터가 있을 경우에는 반복 조회 시에 같은 결과 값을 조회할 수 있음을 보장하지 못합니다.이런 현상을 새롭게 추가된 한 행을 유령(Phantom) 으로 비유하는 Phantom Read 현상이라고 이야기합니다.","phantom-read#Phantom Read":"Repeatable Read 는 하나의 트랜잭션에서 데이터를 반복 조회할 때 다른 트랜잭션에서 수정/추가 한 데이터로 인해 새로 추가된(Phantom) 데이터가 보이는 현상을 의미합니다.","serializable#Serializable":"가장 엄격한 격리수준이지만, 동시성 성능이 급격히 저하될 가능성이 높습니다."}},"/transaction/transactional-annotation":{"title":"Transactional Annotation","data":{}},"/when-you-choose-dbms/sometimes-nosql-is-better-choice":{"title":"Sometimes Nosql Is Better Choice","data":{"nosql이-더-좋은-선택일-경우-feat-subset-패턴#NoSQL이 더 좋은 선택일 경우 (feat. Subset 패턴)":""}},"/transaction/what-is-acid":{"title":"What Is Acid","data":{"트랜잭션의-기본-4-원칙-acid#트랜잭션의 기본 4 원칙 (ACID)":"ACID 는 ANSI 에서 트랜잭션이 갖춰야 할 4가지 성격을 의미하며 아래의 4 단어의 앞글자를 따서 ACID 라고 부릅니다.\nAtomicity (원자성)\n트랜잭션 하나는 하나의 원자적인 단위로 취급되어야 하며, 하나의 트랜잭션 내에서 연산 하나가 실패할 경우 트랜잭션 내부의 모든 연산이 롤백되어야 합니다.\nConsistency (일관성)\n트랜잭션에서 수행하는 연산은 데이터베이스의 무결성 제약 조건이 지켜져야 합니다.\nIsolation (격리성)\n수행중인 트랜잭션은 다른 트랜잭션에 의해 변경되거나 수정되지 않아야 합니다.\n트랜잭션의 4가지 원칙 중 가장 기술적으로 난이도가 높은 원칙이 격리성입니다. ANSI 에서는 네가지 수준의 격리수준을 정의하고 있습니다. 트랜잭션 격리수준에 대해서는 다음 문서에서 자세히 정리할 예정입니다.\nDurability (지속성)\n완료된 트랜잭션은 기록되어야 합니다.\n트랜잭션이 성공했어도 시스템 문제가 발생할 경우, 데이터베이스 로그 등을 이용해 성공한 트랜잭션 내용을 복구할 수 있어야 합니다."}},"/normalization-denormalization":{"title":"Normalization Denormalization","data":{}},"/transaction/what-is-mvcc":{"title":"What Is Mvcc","data":{"mvcc-multi-version-concurrency-control#MVCC (Multi Version Concurrency Control)":"MVCC (Multi Version Concurrency Control) 는 \"다중 버전 동시성 제어\"라고 불립니다.\nMVCC 를 알아보기 전에 먼저 \"동시성제어 (Concurrency Control)\"를 먼저 알아보고, MVCC 는 무엇인지 알아봅니다.","동시성-제어-concurrency-control#동시성 제어 (Concurrency Control)":"주로 트랜잭션의 격리성을 확보하기 위해 동시성 제어가 필요합니다. DBMS 에 다수의 사용자로부터 동시에 트랜잭션이 발생할 때 트랜잭션 사이에 상호간섭이 발생할 수 있는 상황이 발생하는데 이런 상황에 대해 Database 를 보호하는 것을 의미합니다. 동시성을 낮추면 데이터의 일관성이 낮아져서 서로 다른 트랜잭션에서 바라보는 데이터가 다를 경우가 있습니다. 반면 동시성을 높이면 데이터의 일관성은 높아집니다.","동시성-제어의-종류-pessimistic-optimistic#동시성 제어의 종류 (Pessimistic, Optimistic)":"동시성 제어를 위해서는 낙관적 락, 비관적 락을 사용합니다. 낙관적 락의 경우 애플리케이션 레벨에서 시간, 버전 등을 기록해서 이것을 통해서 충돌 여부를 감지하고 변경 여부를 롤백하는 것을 의미합니다. 낙관적 락은 데이터의 버전별로 독자적으로 트랜잭션을 수행할 수 있기 때문에 동시성이 높습니다. 하지만 충돌시 롤백 처리를 직접 구현해야 하고, 충돌 처리 시에 데이터를 불러오거나 하는 등의 작업을 해야 하기에 연산 비용이 크기도 합니다.비관적 락의 경우 데이터베이스에서 제공하는 SELECT FOR UPDATE, SELECT FOR SHARE 와 같은 SQL 을 사용하는 것을 의미합니다. 락을 배타적으로 걸어서 락을 걸기로 선택한 자원에 대한 접근이 제한되게 됩니다. 데이터의 일관성을 높은 수준으로 제공할 수 있고 격리수준을 높여서 다른 트랜잭션의 접근을 방어할 수 있다는 점은 좋습니다. 하지만 배타적으로 락을 걸기 때문에 동시성 성능이 급감하게 되고 데드락이 발생할 확률이 높은 편이기에 대규모 트래픽에서 사용하기에는 적절하지 않습니다.낙관적 락, 비관적 락에 대해 쉬운 자료를 찾고 싶으시다면 낙관적 락과 비관적 락 을 참고해주시기 바랍니다.","mvcc-multi-version-concurrency-control-1#MVCC (Multi Version Concurrency Control)":"트랜잭션의 격리 수준을 보장하기 위해 비관적락, 낙관적 락을 사용해서 동시성 제어를 할 수도 있지만, 상용 DBMS들은 락을 사용하지 않고도 동시성을 제공 가능하도록 다중버전 동시성 제어 (MVCC (Multi Version Concurrency Control)) 기능을 제공합니다.MySQL 의 경우 Undo Segment 방식을 통해 MVCC 기능을 제공하고, PostgreSQL의 경우 MGA 방식을 통해 MVCC 기능을 제공합니다.\nUndo Segment 방식\n최신 데이터는 기존 데이터 블록의 레코드에 반영한다.\n변경 전의 값은 undo 영역이라는 별도의 공간에 저장하고, 갱신에 대한 버전관리를 한다.\n자세한 내용은 우아한 형제들 기술블로그 - Aurora MySQL vs Aurora PostgreSQL 을 참고해주시기 바랍니다.\nMGA 방식\n튜플을 Update 할 때 새로운 값으로 replace 하지 않고 이전 튜플은 유효범위를 마킹해서 처리하는 방식\nMGA 방식은 트리 구조를 이용하는데, 짧은 시간 내에 같은 행을 수정하는 단발성 업데이트 작업의 빈도가 많다면 당연히 MVCC 로 인해 데드 트리가 많이 생기는데, 이 양이 많아지면 N^M 과 같은 어마 어마한 양의 디스크 사용량이 발생할 수 있다는 사실을 기억해두어야 합니다.\n따라서 PostgreSQL 은 Insert/Select 위주의 서비스라면 적합하겠지만, Update 가 많은 시스템에는 MVCC 로 인해 운영상에 이슈가 자주 발생할 소지가 있습니다. 예를 들어 증권데이터처럼 주식에 대한 현재가격이 계속해서 변해야 하는 시스템에는 MVCC 로 인해 발생하는 데드 튜플들을 청소해줘야 하므로 주기적으로 Vaccum 을 수행해줘야 하고, 쓰지 않는 디스크 공간의 파편화가 자주 발생하는 등 부적합한 요소들이 많습니다.\n자세한 내용은 PostgreSQL MVCC/SQL 을 참고해주시기 바랍니다.","dbms-별-트랜잭션-격리-수준#DBMS 별 트랜잭션 격리 수준":"DBMS별로 기본으로 설정된 트랜잭션 격리수준은 아래와 같습니다.\nMySQL (InnoDB 스토리지 엔진을 사용할 경우)\nRepeatable Read\nOracle\nRead Committed\nPostgresql\nRead Committed\n대부분의 Database는 Read Committed 이상의 레벨을 기본 격리수준으로 채택하고 있습니다."}},"/when-you-choose-dbms/when-you-choose-mysql-postgresql":{"title":"When You Choose Mysql Postgresql","data":{"mysql-postgresql-선택시-고려해볼-것들#MySQL, PostgreSQL 선택시 고려해볼 것들":""}},"/transaction/transactional-propagation-option":{"title":"Transactional Propagation Option","data":{}}}