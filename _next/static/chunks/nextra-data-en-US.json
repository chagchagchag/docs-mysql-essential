{"/about":{"title":"About","data":{"":"This is the about page! This page is shown on the navbar."}},"/":{"title":"Introduction","data":{"":"안녕하세요 :) 이 곳은 MySQL 의 기본적인 내용들을 정리하는 페이지입니다.개인적으로 오래 전에 여기 저기에 정리해둔 문서들을 보면서 정신이 산만해져서 하나의 페이지에 모아두면 좋겠다고 생각해서 개설했고, 가급적 빠른 시일 내에 정리되도록 노력중입니다."}},"/jpa-vs-mybatis-jdbctemplate":{"title":"Jpa Vs Mybatis Jdbctemplate","data":{"jpa-vs-mybatis-jdbctemplate#JPA vs Mybatis, JdbcTemplate":"굉장히 뜨거운 논쟁이고 Mybatis 가 좋냐 JPA가 좋냐이런 질문을 하는 분들은 대부분 본인이 원하는 답이 나오기를 원하고 질문하는 경우가 많아 답답한 적도 많고 진이 빠진 적이 많은 것 같습니다.개인적으로는 JPA, Querydsl, Mybatis, JdbcTemplate 모두 개발에서 잘 사용해왔고, 어느 것 하나에 우위에 있다고 하거나 특히 선호하지는 않습니다. 물론 Mybatis 를 사용한적이 오래되서 조금 피하는 면이 있지만 업무에서 사용할 경우 Mybatis 역시 모듈화를 잘 해두면 테스트가 잘 되는 구조로 만드는게 가능했고, 성능을 고려해서 JPA 기반의 고빈도 트래픽 Insert 로직을 JdbcTemplate 기반의 코드로 전환해본 경험도 있습니다.JPA 를 사용한다고 해서 JPA 의 Write Behind 로 인해 성능이 개선되고 이런 이슈들이 있거나 이런 이론적인 이야기는 할수는 있겠지만, 최근 R2DBC 에서는 Write Behind가 적용되는 것도 아니고 그렇게 성능 상에 있어서 Write Behind 같은 개념들이 특장점이 크다고는 생각하지는 않습니다. 단순히 DBMS 클라이언트 레벨에서의 소소한 캐싱이 그렇게 큰 역할을 한다고 이야기하기에는 조금 아쉬운 면이 많습니다.가장 중요한 것은 DBMS 의 특성을 이해해서 성능이 잘 나오도록 쿼리를 사용하고, DBMS 에 맞도록 서비스를 운영하는 것이 중요하다고 생각합니다.저는 DBMS의 커버링 인덱스의 개념에 대해 아는지 모르는지에서 이런 관점이 바뀐다고도 생각하는 편입니다. 만약 같은 쿼리에 대해서 커버링 인덱스만 거쳐서 필수적인 PK를 가져온 뒤에 서브쿼리를 이용해서 필요한 로우만 타격해서 데이터를 가져올 경우 성능상에 이점이 있습니다. 이렇게 로직을 작성하는 것은 제품을 생각해서 개발하는 것이라고 생각합니다.반면, 커버링인덱스의 개념이 적용되지 않은 채로 모든 컬럼을 함께 조회해온다면 소규모 개발 그룹이거나 어드민 서비스를 개발한다면 어느 정도는 인정이 되겠지만, 상용서비스 개발 시에 이렇게 한다면 백엔드 개발 스터디를 더 해야 하는 것이 아닐까 하는 생각이 있습니다.이런 경우 JPQL 을 적절하게 활용해서 쿼리 최적화를 하거나, JdbcTemplate, Mybatis 를 적절하게 활용해서 배포 전에 쿼리 튜닝을 어느 정도 해서 배포를 하는 것도 중요한 습관이라고 생각합니다."}},"/memory-disk-wal":{"title":"Memory Disk Wal","data":{"memory-vs-disk-wal#Memory vs Disk, WAL":"데이터베이스는 디스크에 데이터를 기록합니다. 그런데 디스크는 메모리에 비해 I/O 작업 비용이 꽤 큽니다.이런 이유로 데이터베이스는 메모리를 이용해서 메모리 캐시 히트율을 높여서 디스크로의 접근을 최소화합니다.하지만 데이터베이스가 메모리만 사용할 수는 없습니다. 메모리의 가격이 디스크보다 비싸기에 메모리를 방대하게 사용하는 것은 쉽지 않습니다. 또한 메모리는 휘발성을 가진 저장장치이기에 메모리가 off 되었을 때에 대책이 필요합니다.이런 이유로 메모리에 데이터를 쓰기 전에 디스크에 쿼리 기록을 남깁니다. 그리고 디스크에는 랜덤접근보다는 순차접근이 효율적이기에 쿼리 로그는 순차 접근 방식으로 기록되며, 현재 읽고 있는 위치를 기록하게 됩니다. 이렇게 되면 장애 발생시 마지막으로 읽었던 위치의 쿼리 로그와 여러 정보들을 조합해서 메모리와 디스크 사이의 데이터 불일치문제를 해결할 수 있게 됩니다.이번 문서에서는 이 과정에 대해 세부적으로 설명합니다.","메모리-쓰기-시-장애를-보완---wal#메모리 쓰기 시 장애를 보완 - WAL":"데이터베이스의 데이터는 최종적으로 디스크에 저장됩니다. 디스크는 메모리에 비해 성능이 많이 떨어집니다. 따라서 데이터베이스 성능에 있어서 핵심으로 두는 중점사항은 \"디스크로의 랜덤I/O 를 최소화하는 것\" 입니다.디스크 접근에는 순차 I/O 와 랜덤 I/O 가 있습니다. 순차 I/O는 가장 마지막에 읽었던 위치만 알고 있으면 되기에 쓰기 위치를 파악하는데에 있어서 많은 시간이 소요되지 않습니다. 랜덤 I/O 의 경우 원하는 데이터의 위치를 찾은 후 그 위치에 쓰기/수정 작업을 해야 하는데 이때 디스크에 접근하는 비용이 메모리에 접근하는 것에 비해 꽤 큽니다.이런 경우 디스크에 접근하는 횟수를 줄이는 대신 메모리에 캐시 히트율을 높인다면 쓰기에 소요되는 비용이 줄어듭니다. 하지만 이 경우 메모리의 데이터가 유실될 수 있다는 점 역시 고려해야 합니다. 데이터베이스에 장애가 발생하면, 메모리에 있는 내용들은 디스크에 반영되지 않기에 디스크의 내용과 메모리의 내용이 일치하지 않는 상황이 발생할 수 있습니다. 이런 이유로 대부분의 데이터베이스는 이런 경우에 대비해 WAL(Write Ahead Log) 기반으로 동작합니다.\nWAL (Write Ahead Log)\n데이터베이스는 쿼리 수행 전에 어떤 쿼리를 사용하는지 실행하려 했던 쿼리들의 기록을 디스크에 순차기록을 해둡니다. 따라서 장애 등으로 인해 수행되지 않은 쿼리 들은 이 WAL 이라는 곳에서 읽어서 장애를 복구할 때 WAL에 쌓아둔 실행되지 않는 쿼리를 디스크에 반영합니다. 이렇게 해서 유실될 수 있는 쿼리 요청으로 인해 장애 직전 메모리에 남아있었던 결과와 디스크에 기록된 내용들이 달라질 수 있는 문제로 인한 데이터의 싱크가 깨지는 현상을 해결이 가능합니다. 이렇게 실행하려는 쿼리의 기록을 디스크에 순차 기록을 해두어 데이터의 싱크가 깨지는 현상을 방지하는 기술을 WAL(Write Ahead Log) 라고 부릅니다.","저장장치-별-latency#저장장치 별 Latency":"Latency Numbers Every Programmer Should Know\ngist.github.com/jboner/latency.txt"}},"/mysql-architecture":{"title":"Mysql Architecture","data":{"mysql-구조#MySQL 구조":"","쿼리파서#쿼리파서":"SQL 을 파싱해서 Syntax Tree 를 만듭니다. 이 과정에서 문법 검사가 이뤄집니다.마치 javascript 의 정적 페이지를 빌드할 때 linting 등의 밸리데이션 작업을 하듯 이 과정에서 문법검사등을 수행합니다. 문법검사가 끝나면 Syntax Tree 를 만듭니다.쿼리 파서가 만들어내는 Syntax Tree 에 대해서는 https://observablehq.com/@john-guerra/sql-query-visualizer에서 자세히 설명하고 있습니다.\nSELECT distinct * FROM A, B WHERE name=\"John\" and age> 32 \r\n\tand name not in (select name  from A where name!= \"John\") \r\n\tGROUP BY name\r\n\tLIMIT 10\n위와 같은 쿼리에 대해서 쿼리 파서는 아래와 같은 Syntax Tree 를 만들어냅니다.","전처리기#전처리기":"쿼리 파서가 만든 Syntax Tree 를 토대로 전처리를 시작합니다. 테이블,컬럼 존재여부, 접근 권한 등과 같은 Semantic 오류를 검사합니다.","옵티마이저#옵티마이저":"불필요한 조건을 제거하고, 테이블 순서, 통계정보를 바탕으로 전략을 결정합니다. 이 과정을 실행계획 수립이라고 합니다. 쿼리를 처리하기 위한 여러 방법들을 만들고 이 방법들에 대한 비용 정보, 테이블의 통계 정보를 이용해 비용을 산정하는 역할을 수행합니다.옵티마이저가 선택하게 되는 전략에 따라 성능이 많이 달라지기도 하는데, 가끔 나쁜 판단이 이뤄질 수도 있어서 개발자가 힌트를 사용하거나 explain 명령을 통해 도움을 주기도 합니다.","쿼리-실행기#쿼리 실행기":"옵티마이저가 선택한 전략을 바탕으로 쿼리를 실행하는데, 이때 쿼리 실행기는 Handler API 라는 것을 사용해 스토리지 엔진에 요청을 수행합니다.","스토리지-엔진#스토리지 엔진":"스토리지 엔진은 데이터를 가져오거나 저장하는 역할을 수행합니다. Handler API 에 맞춰서 플러그인 형태로 직접 구현해서 스토리지 엔진에 접근하는 프로그램을 개발하는 것 역시 가능합니다.MySQL에는 InnoDB, MyIsam 등 여러 종류의 스토리지 엔진이 존재하는데, 8.0 이후 부터는 InnoDB 엔진이 디폴트 스토리지 엔진이 되었고, 많은 사람들이 MySQL 의 스토리지 엔진을 이야기할 때 대부분 InnoDB 엔진을 이야기합니다.InnoDB 엔진은 클러스터 인덱스, Redo-Undo 로그, Buffer pool 등과 같은 특징을 가집니다.클러스터 인덱스는 쉽게 말해 인덱스의 데이터 주소가 가까운 곳이 서로 클러스터 처럼 모여있는 것을 의미하는데 인덱스의 리프노드를 PK로 구성하고 인덱스 역시도 PK기반으로 구성되게끔 해서 커버링 인덱스의 성격을 가지게 되어 데이터가 지역성을 갖추게 되어서 데이터의 조회가 효율적으로 이뤄지게 하는 것을 의미합니다.Redo-Undo 로그 는 MySQL 이 동시성환경에서 MVCC 시에 사용하는 전략을 의미합니다."}},"/mysql-index":{"title":"Mysql Index","data":{"인덱스#인덱스":"예를 들어 아래와 같은 데이터가 있습니다. 문자 C 를 찾으려면 끝까지 모두 읽어야 합니다.\nD\tZ\tB\tA\tK\tC\t\n이번에는 위의 데이터를 오름차순으로 정렬했습니다. 정렬된 표에서는 C 가 3번째에 있다는 사실이 확실하기에 더 빠르게 읽어올 수 있습니다.\nA\tB\tC\tD\tK\tZ","인덱스를-사용하는-이유#인덱스를 사용하는 이유":"무작위로 데이터의 위치를 O(N)으로 탐색하기 보다는 이렇게 정렬된 자료구조를 통해 데이터를 접근한다면 데이터를 탐색해야 하는 범위가 축소되기에 데이터의 접근 속도가 월등히 빨라지게 됩니다. 즉, 인덱스를 사용하는 이유는 '인덱스의 탐색 범위'를 줄여서 접근 속도를 최적화하기 위해서입니다.","인덱스-자료구조의-원리#인덱스 자료구조의 원리":"인덱스는 하나의 자료구조입니다. 데이터의 주소들을 특정 순서로 기억하고 있는 하나의 목차와 같은 역할을 합니다. 예를 들어 아래와 같은 테이블이 있습니다.\n데이터 주소\tTicker\t회사명\t시가총액\t1\tMSFT\tMicrosoft\t3.049 T\t2\tNVDA\tNvdia\t1.97 T\t3\tAAPL\tApple\t2.818 T\t\n만약 위의 데이터를 시가총액이 가장 낮은 회사를 찾는다거나 시가 총액이 가장 높은 회사를 찾는 다거나 하는 조회를 하려면 아래와 같은 자료구조를 미리 만들어두면 조회 성능상에 이점이 생깁니다.\n시가총액\t데이터 주소\t1.97 T\t2\t2.818 T\t3\t3.049 T\t1\t\n만약 시가총액이 가장 낮은 회사를 찾아야 할 경우 가장 맨 처음에 나타난 1.97T 에 대한 데이터는 데이터 주소가 2 이고 데이터 주소 2 에 대한 원본 데이터를 확인해보면 NVDA 인 것을 확인 가능합니다.만약 시가총액이 가장 높은 회사를 찾아야 한다면 가장 마지막에서 첫번째 데이터를 읽으면 되고, 3.049 T 에 대해 데이터 주소가 1인데 데이터 주소 1에 대한 원본데이터를 확인해서 MSFT 라는 것을 확인 가능합니다.","b-tree---인덱스의-자료구조#B+ Tree - 인덱스의 자료구조":"","btree-학습자료#B+Tree 학습자료":"https://www.cs.usfca.edu/~galles/visualization/BPlusTree.html","여러가지-자료구조들과의-비교#여러가지 자료구조들과의 비교":"List\n정렬되지 않았을 때 : O(n)\n정렬된 리스트에서는 : O(logN)\n정렬되지 않은 리스트의 정렬 시간 복잡도는 : 평균 (Mlog(N))\nArrayList와 같은 구조일 경우 삽입/삭제 시 비용이 높다.\nHashMap\n단건 검색 속도 : O(1)\n범위 탐색 : O(N)\n전방 일치 탐색 불가 (e.g. like 'AB%')\nTree\n트리의 높이에 따라 시간복잡도가 결정된다.\n트리의 높이를 최소화 하는 것이 중요\n한쪽으로 노드가 치우치지 않도록 하는 균형잡힌 트리를 사용\ne.g. Red Black Tree, B+Tree, ...\nRed Black Tree 는 각 노드가 하나의 데이터 역할을 하고, B+Tree 의 각 노드는 리프노드의 주소 역할을 수행","btree#B+Tree":"B+Tree 는 데이터 자체는 하나의 링크드리스트로 구성되어 있고, 이 링크드 리스트는 트리의 리프로 구성되어 있습니다. 그리고 이 데이터의 주소로 구성된 트리를 이진탐색하면서 원하는 위치를 찾기에, 리프노드에 구성된 링크드 리스트에서 원하는 위치를 빠르게 찾아낼 수 있습니다.예를 들면 1~17 까지의 데이터를 추가할 때 위와 같이 B+Tree 가 생성됩니다. 가장 마지막 리프노드에 1~17 데이터가 이어져있고, 각각의 트리는 데이터의 주소를 이진탐색할 수 있도록 구성되어 있음을 확인 가능합니다.데이터가 insert 될 때 어떻게 동작하는지는 https://www.cs.usfca.edu/~galles/visualization/BPlusTree.html 에서 확인 가능합니다.\nB+Tree 는 기본적으로 아래의 성격을 가집니다.\n삽입/삭제 시 항상 균형을 유지\n하나의 노드가 여러개의 자식 노드를 가지는 것 가능\n리프노드에만 데이터가 존재하기에 연속적인 데이터에 접근 시에 장점을 가짐","mysql-의-btree#mysql 의 B+Tree":"mysql의 인덱스는 B+Tree 의 리프노드에 PK를 가지고 있습니다. 참고로 Oracle 에서는 B+Tree 의 리프노드에 데이터의 주소를 가지고 있습니다.이렇게 PK를 B+Tree 의 리프노드에 가지고 있는 것은 PK를 클러스터드 인덱스로 가지고 있기에 용이한 구조임을 유추할 수 있습니다.아래의 그림은 Canada 라는 인덱스 키를 검색할 때 B-Tree 의 주소를 어떻게 검색하는지 절차를 그림으로 그린 것입니다.","클러스터-인덱스#클러스터 인덱스":"MySQL 의 PK 는 클러스터 인덱스로 이루어져 있습니다.MySQL 의 PK가 아닌 일반 인덱스 역시 MySQL의 B+Tree 는 PK기반으로 구성하기에 일반 인덱스 역시 내부적으로는 PK를 가지며 클러스터 인덱스로 구성되어 있습니다.","클러스터-인덱스-장단점#클러스터 인덱스, 장단점":"클러스터 인덱스라는 것은 인덱스가 특정 범위를 두고 모여 있는 인덱스라는 것을 의미합니다. 클러스터 인덱스의 장점은 데이터의 지역성이 이뤄지기 때문에 데이터 조회시 조금 더 빠른 성능을 낼 수 있다는 점입니다. 반면, 데이터가 새로 들어올 때 재조정을 해야 할수도 있기 때문에 클러스터 인덱스가 리빌드 될 때의 오버헤드는 단점이 될 수 있습니다.예를 들어 아래와 같은 데이터가 있다고 해보겠습니다.\n클러스터 인덱스 키\t데이터 주소\t100\tA\t200\tB\t300\tC\t500\tD\t\n이 상황에서 아래와 같이 새로운 데이터인 400 이 들어오는 경우에는 500 에 해당하는 클러스터 인덱스 키에 대한 데이터 주소는 재배치 됩니다.\n클러스터 인덱스 키\t데이터 주소\t100\tA\t200\tB\t300\tC\t400 (새로들어옴)\tD\t500\tE\t\n이렇게 적은 데이터에서는 조금만 이동되었지만, 데이터가 많아지면 재배치할 데이터들이 많아지게 됩니다.","인덱스-역시-pk로-이뤄져-있으며-클러스터-인덱스로-구성#인덱스 역시 PK로 이뤄져 있으며 클러스터 인덱스로 구성":"MySQL 의 PK가 아닌 일반 인덱스 역시 MySQL의 B+Tree 는 PK기반으로 구성하기에 일반 인덱스 역시 내부적으로는 PK를 가지며 클러스터 인덱스로 구성되어 있습니다.","커버링-인덱스#커버링 인덱스":"커버링 인덱스는 데이터가 담긴 테이블을 직접 접근하지 않고도 인덱스로만 원하는 데이터에 접근할 수 있도록 구성한 인덱스를 의미합니다.예를 들어 아래와 같은 데이터가 있다고 해보겠습니다.\nid(PK)\tticker\tmarket_cap\t1\tAAPL\t2.818\t2\tMETA\t1.234\t3\tMSFT\t3.049\t4\tNVDA\t1.97\t\n그리고 시가총액인 market_cap 에 대한 인덱스가 아래와 같이 구성되어 있다고 해보겠습니다.\nmarket_cap\tid(PK)\t1.234\t2\t1.97\t4\t2.818\t1\t3.049\t3\t\n이 때 아래와 같은 SQL은 테이블을 탐색하지 않고도 인덱스만으로도 원하는 데이터를 인출해올 수 있습니다.\nSELECT market_cap\r\nFROM stock_symbols\r\nWHERE market_cap > 2;\n아래의 SQL 역시 원본 테이블을 탐색하지 않고도 인덱스만으로도 원하는 데이터를 인출해올 수 있습니다.\nSELECT id, market_cap\r\nFROM stock_symbols\r\nWHERE market_cap > 2;\n그런데 이때 Ticker 데이터 역시 가져와야 하는 상황이 있습니다. 이런 경우에는 아래와 같은 SQL 을  사용한다면 커버링 인덱스를 거치게 되어서 데이터를 필요한 데이터만 접근해서 조회해오기에 효율적으로 조회할 수 있습니다.\nSELECT A.id, A.ticker, A.market_cap\r\nFROM stock_symbols A\r\nINNER JOIN (\r\n    SELECT id, market_cap\r\n    FROM stock_symbols\r\n    WHERE market_cap > 2\r\n) B\r\n ON A.id = B.id\n커버링 인덱스를 사용하게 되면 order by, offset, limit 등을 사용하는 것으로 인한 불필요한 데이터 블록에 대한 접근을 커버링 인덱스를 이용해서 최소화할 수 있게 됩니다.","인덱스-사용-시-주의해야-하는-점들#인덱스 사용 시 주의해야 하는 점들":"인덱스 사용 시 주의해야 할 점은 아래와 같습니다\n인덱스 필드 가공은 피하는 것이 좋다\n복합인덱스 사용시에는 복합된 컬럼을 모두 사용해야만 인덱스를 조회하게 된다\n기본적으로 하나의 쿼리는 하나의 인덱스만 탄다\nSQL에 대해서 인덱스가 동작하지 않는 경우가 있을 수 있기 때문에, 성능이 중요한 쿼리일 경우 explain 을 통해서 확인하는 습관을 들이는 것을 추천합니다. 또한 무작정 인덱스를 사용한다고 해서 항상 성능이 향상된다는 고정관념 역시 탈피해야 하고 무분별한 인덱스 추가작업 인지 역시 충분히 고민을 해봐야 합니다. 인덱스를 사용하면 조회속도에 이점을 얻을 수는 있지만, 새로운 데이터 추가 시에 데이터베이스 내부적으로는 커버링 인덱스, B+Tree 의 데이터 위치들을 재정렬하는 등의 작업들이 일어납니다. 너무 과도한 인덱스 사용보다는 꼭 필요한 필드를 인덱스로 선택해서 사용하는 것을 권장합니다.흔히 인덱스를 사용하는 것에 대해 쓰기를 희생하고 조회를 얻는 것 이라는 이야기를 합니다. 이 말을 떠올려서 꼭 필요한 곳에 인덱스를 사용하도록 고민을 해봐야 할 것 같습니다.","인덱스-필드-가공은-피하는-것이-좋다#인덱스 필드 가공은 피하는 것이 좋다":"인덱스 필드를 가공하면 인덱스를 타지 못하게 됩니다.예를 들어 아래의 테이블이 있다고 하겠습니다. market_cap 필드는 biginteger 타입으로 선언되어 있습니다.\nid(PK)\tticker\tmarket_cap (indexed)\t1\tAAPL\t2.818\t2\tMETA\t1.234\t3\tMSFT\t3.049\t4\tNVDA\t1.97\t\n그리고 아래의 쿼리는 인덱스를 타지 못합니다. 자료형이 다르기 때문입니다. 이렇게 자료형이 다른 경우 옵티마이저는 내부적으로  to string 처리를 하게 되어서 인덱스를 통한 검색이 이뤄지지 않습니다.\nSELECT * \r\nFROM stock_symbols\r\nWHERE market_cap = '2.818'\n아래의 쿼리 역시 인덱스를 타지 못합니다. 인덱스 필드를 가공하고 있기 때문입니다.\nSELECT * \r\nFROM stock_symbols\r\nWHERE market_cap*100 = 2.818","복합인덱스-사용시에는-복합된-컬럼을-모두-사용해야만-인덱스를-조회하게-된다#복합인덱스 사용시에는 복합된 컬럼을 모두 사용해야만 인덱스를 조회하게 된다":"예를 들어 아래와 같은 테이블이 있다고 해보겠습니다. 복합 인덱스로 ticker, marekt_cap 기반의 복합인덱스를 구성했습니다.\nid(PK)\tticker(indexed a1)\tmarket_cap (indexed a2)\tceo\t1\tAAPL\t2.818\tTim Cook\t2\tMETA\t1.234\tMark Zuckerberg\t3\tMSFT\t3.049\tSatya Nadella\t4\tNVDA\t1.97\tJen-Hsun Huang\t\n이 경우 인덱스는 아래와 같이 구성됩니다.\nid(PK)\tticker(indexed a1)\tmarket_cap (indexed a2)\t1\tAAPL\t2.818\t2\tMETA\t1.234\t3\tMSFT\t3.049\t4\tNVDA\t1.97\t\n복합인덱스 조합은 { ticker, market_cap } 조합에 대해서 ticker 에 대해 먼저 정렬된 행에 대해서 market_cap 에 대해 정렬한 결과를 인덱스로 가지고 있는데, 만약 아래의 쿼리를 수행한다면 아래의 쿼리는 인덱스를 거치지 못하게 됩니다.\nSELECT id, ticker, market_cap\r\nFROM stock_symbols\r\nWHERE market_cap > 1;\n왜냐하면 market_cap 은 복합 키 내에 보조적인 역할을 할 뿐이기에 market_cap > 1 처럼 market_cap 필드 하나에 대해서만 위치를 조회하는 것은 전혀 인덱스를 거치지 못합니다.","기본적으로-하나의-쿼리는-하나의-인덱스만-탄다#기본적으로 하나의 쿼리는 하나의 인덱스만 탄다":"하나의 쿼리는 하나의 인덱스만 탑니다. 여러 인덱스 테이블을 동시에 탐색하는 것은 기본적으로는 불가능하며, index merge hint 를 사용한다면 가능하기는 합니다. 따라서 where , order by , group by 를 사용하는 쿼리에서는 인덱스를 잘 고려해야 합니다."}},"/normalization-denormalization":{"title":"Normalization Denormalization","data":{}},"/query-cache":{"title":"Query Cache","data":{"쿼리-캐시#쿼리 캐시":"","쿼리-캐시란#쿼리 캐시란":"쿼리캐시에 SQL 과 데이터를 매핑해서 가지고 있다가 똑같은 SQL이 왔을때 캐시에 보관해둔 결과물을 응답하도록 캐시에 SQL의 결과를 보관하고 있는 것을 의미합니다.쿼리 캐시는 데이터를 캐시하기 때문에 테이블의 데이터가 변경되면 캐시의 데이터도 함께 업데이트해줘야 합니다. 이런 업데이트 작업으로 인해 락(Lock) 이슈가 있었고 이런 이슈는 이익보다는 단점도 크고 캐시 데이터 관리에 대한 비용(성능상의 단점)이 컸기에 8.0 이후로는 MySQL 에서 쿼리 캐시 기능은 폐기 되었습니다.다른 데이터베이스에도 쿼리 캐시와 유사한 기능이 있습니다. 오라클에서도 쿼리캐시와 비슷한 기능을 소프트 캐시 라는 이름으로 제공하기는 하지만, MySQL 처럼 SQL에 대한  데이터 까지는 매핑하지는 않고 실행 계획 까지만 캐싱을 합니다. 즉, 오라클은 MySQL 과 쿼리 캐시가 다르며 실행 계획까지만 제공한다는 점에서 MySQL과는 차이가 있습니다.","mysql-50--mysql-80#MySQL 5.0 → MySQL 8.0":"MySQL 5.0 까지는 쿼리 캐시 기능이 있었지만, MySQL 8.0 부터는 쿼리 캐시 기능이 폐기되었습니다.테이블의 데이터가 변경되면, 쿼리캐시에도 똑같이 변경된 내용을 반영해야 하는데 이 과정에서 락과 같은 이슈가 있었고 쿼리 캐시로 인해 이점보다는 문제점이 크기에 8.0 이후로는 폐기되었습니다.","참고-오라클--소프트파싱-하드파싱#참고) 오라클 : 소프트파싱, 하드파싱":"오라클에는 소프트파싱, 하드파싱이라는 개념이 있습니다.\r\n소프트파싱, 하드 파싱의 개념은 아래와 같습니다.소프트파싱\n실행 계획을 캐시에서 찾아서 옵티마이저 과정 생략 후 실행단계로 넘어갑니다.\n실행 계획 까지만 캐싱이 됩니다.\n하드 파싱\n실행 계획을 캐시에서 찾지 못했을 경우 옵티마이저 과정을 거친 후 실행단계로 넘어갑니다.\n하지만 오라클은 5.0 대의 MySQL 처럼 모든 SQL과 매핑해서 데이터까지 캐싱하지는 않습니다. \n물론 힌트나 설정으로 모든 SQL과 매핑해서 데이터까지 캐싱하는 것이 가능하기는 하지만  오라클에서 기본적으로 제공되는 기능은 아닙니다."}},"/transaction/intro":{"title":"Intro","data":{"소개#소개":"보통 IoT나 지표데이터 수집, 블로그 같은 경우 격리수준이 높을필요가 없을 수도 있습니다. 하지만 결제,송금,뱅킹,포인트 같은 영역에서는 트랜잭션이 중요합니다.데이터베이스는 데이터를 처리하고 커밋하기 까지의 단위를 트랜잭션 단위로 처리할 수 있도록 합니다. 그리고 이 트랜잭션이라는 기준을 갖추기 위해서는 원자성, 일관성, 격리성, 지속성 이라는 요소를 갖춰야 합니다.쉽게 설명하면 트랜잭션 하나는 하나의 원자적인 단위로 취급되어 트랜잭션 내에서 하나가 실패할 경우 트랜잭션 내부의 모든 연산이 롤백되어야 하는 원자성, 트랜잭션에서 수행하는 연산은 데이터베이스의 무결성 제약 조건이 지켜져야 한다는 일관성, 수행중인 트랜잭션은 다른 트랜잭션에 의해 변경되거나 수정되지 않아야 한다는 격리성, 완료된 트랜잭션은 기록되어야 한다는 지속성 이라는 원칙이 있습니다.이번 카테고리에서는 이런 내용들을 다루며, SQL로는 이렇게 트랜잭션을 열고 닫고, Spring 에서는 어떻게 선언적인 트랜잭션을 사용하는지, 트랜잭션 전파 옵션은 무엇이 있는지를 정리합니다.개인적으로 시간이 부족하기도 하지만, 가급적이면 빠른 시일 내에 정리하도록 하겠습니다."}},"/transaction/transaction-be-careful":{"title":"Transaction Be Careful","data":{"트랜잭션-사용시-주의점#트랜잭션 사용시 주의점":"트랜잭션은 하나의 세션입니다. 이러한 세션들이 수행하는 연산이 길게 늘여저서 오랫동안 시간을 점유한다면, Database 의 동시성 성능을 저하시키는 요인이 발생하게 됩니다.따라서 하나의 트랜잭션 단위에서 너무 많은 연산을 수행한다거나 오래 걸리는 작업을 수행하지 않도록 주의가 필요합니다.배치나 일괄 정산 작업 등을 뒷단에서 수행하는 서비스를 운영하는 것이 아니라면 가급적 트랜잭션은 짧게 가져가는 편이 좋습니다."}},"/transaction/transaction-isolation-level":{"title":"Transaction Isolation Level","data":{"트랜잭션-격리수준#트랜잭션 격리수준":"트랜잭션의 격리성을 확보할 때 격리 수준을 4가지 단계로 제공할 수 있습니다. 격리수준이 낮은 수준에서 높은 수준으로 나열해보면 아래와 같습니다.\nRead Uncommitted (커밋되지 않은 읽기) : Dirty Read, Non Repeatable Read, Phantom Read 발생\nRead Committed (커밋된 읽기) : Non Repeatable Read, Phantom Read 발생\nRepeatable Read (반복 가능한 읽기) : Phantom Read 발생\nSerializable (직렬화 가능) : 가장 엄격한 격리수준\n각각의 격리 수준에서 발생하는 나타나는 현상들을 정리하면 아래와 같습니다.\n\tDirty Read\tNon Repeatable Read\tPhantom Read\tRead Unommitted\t발생\t발생\t발생\tRead Committed\t\t발생\t발생\tRepeatable Read\t\t\t발생\tSerializable Read\t\t\t\t\n아래에서부터는 각각의 트랜잭션 격리수준과 발생할 수 있는 현상을 예를 들어 설명합니다.","read-uncommitted#Read Uncommitted":"Dirty Read 가 발생합니다.\n커밋되지 않은 것이라도 읽어들일 수 있는 격리 수준입니다. 트랜잭션에서 커밋하지 않은 수정 중인 내용이 다른 트랜잭션에 의해 읽을 수 있는 격리수준으로 가장 낮은 수준의 격리 수준입니다. 만약 다른 트랜잭션으로부터 읽어들인 데이터가 커밋되지 않은 데이터인데 그 데이터가 롤백된다면 데이터의 정합성에 문제가 생깁니다.","dirty-read-현상#Dirty Read 현상":"트랜잭션 t1 이 데이터를 수정하고 있고 커밋하지 않은 상황에서 트랜잭션 t2 가 t1이 커밋하지 않은 데이터를 읽어들일 수 있는 현상입니다. 만약 트랜잭션 t2가 Dirty Read 한 데이터를 사용하고 있는 중에 t1 이 수정 중인 데이터를 롤백한다면 데이터의 정합성에 문제가 생깁니다.은행 송금을 예로 들면 Read Uncommitted 에서 발생할 수 있는 Dirty Read 현상은 아래와 같은 장애를 일으킬 수 있습니다.","read-committed#Read Committed":"Non Repeatable Read 가 발생합니다.\n다른 트랜잭션에서 커밋된 데이터를 읽어들일 수 있는 격리수준을 의미합니다. 커밋된 데이터를 읽어들이기에 롤백하지 못한 데이터를 읽게 되는 불상사는 없습니다. 하지만 다른 트랜잭션에서 수정 후 커밋을 한 데이터를 읽어들이기에 조회 작업 도중에 다른 트랜잭션에서 같은 데이터에 대한 수정본 커밋을 한다면 수정본이 읽히는 현상인 Non Repeatable Read 현상이 발생합니다.","non-repeatable-read-현상#Non Repeatable Read 현상":"은행 송금을 예로 들면 Read Committed 에서 발생할 수 있는 Non Repeatable Read 현상은 아래와 같은 상황이 발생합니다.","repeatable-read#Repeatable Read":"Phantom Read 가 발생합니다.\nRepeatable Read 격리 수준은 Read Committed 가 보장하지 못하는 수정/커밋 된 데이터에 대해 Repeatable Read 가 가능하도록 하는 격리 수준입니다. Repeatable Read 는 다른 트랜잭션에서 수정/커밋 했어도 한번 조회했던 데이터를 조회하면 그 데이터에 대해서는 같은 데이터가 조회됨을 보장합니다.하지만 새롭게 추가된 데이터가 있을 경우에는 반복 조회 시에 같은 결과 값을 조회할 수 있음을 보장하지 못합니다.이런 현상을 새롭게 추가된 한 행을 유령(Phantom) 으로 비유하는 Phantom Read 현상이라고 이야기합니다.","phantom-read#Phantom Read":"Repeatable Read 는 하나의 트랜잭션에서 데이터를 반복 조회할 때 다른 트랜잭션에서 수정/추가 한 데이터로 인해 새로 추가된(Phantom) 데이터가 보이는 현상을 의미합니다.","serializable#Serializable":"가장 엄격한 격리수준이지만, 동시성 성능이 급격히 저하될 가능성이 높습니다."}},"/transaction/transactional-annotation":{"title":"Transactional Annotation","data":{"스프링의-transactional#스프링의 @Transactional":"아래와 같이 댓글을 insert 하고, 집계 테이블을 카운트하는 SQL 이 있다고 해보겠습니다. 댓글 추가 시에는 본문에 대한 댓글 집계 테이블을 업데이트 해줍니다.\nSTART TRANSACTION;\r\n\r\n-- (1) 댓글 작성 \r\nINSERT INTO comment (\r\n    title, content, author_id, updated_dt\r\n)\r\nVALUES(\r\n    'Hello', 'Great Hello World', 1, '2024-02-28'\r\n);\r\n\r\n-- (2) 원글에 대한 댓글 개수 카운팅\r\nINSERT INTO content_comment_cnt(\r\n    content_id, comment_cnt\r\n)\r\nVALUES (\r\n    1, 1\r\n)\r\nON DUPLICATE KEY UPDATE\r\n     comment_cnt = comment_cnt + 1;\r\n\r\n\r\n-- (3) 사용자 활동 기록 추가\r\nINSERT INTO user_activity_history(\r\n    activity_type, created_dt\r\n)\r\nVALUES(\r\n    'CREATE_COMMENT', '2024-02-28 19:30:30'\r\n)\r\n\r\nCOMMIT;\n(1) 까지는 런타임 에러 없이 잘 수행되었다고 가정하겠습니다. (2) 에서는 댓글 개수 카운팅을 진행해서 본문에 대한 댓글 개수를 업데이트 해줍니다.(3) 에서는 사용자 활동 기록을 추가합니다.그런데 만약 (3) 에서 테이블에 데이터를 insert 하는 도중에 activity_type 의 글자수 제한을 넘어서서 INSERT 에러가 났을 경우에는 어떻게 해야 하는 것일까요?\n사용자 활동 기록이 중요하고, 활동기록 없이는 댓글 역시도 의미가 없는 비즈니스 규칙을 세워둔 상태라면 같은 트랜잭션에 있는 (1) 댓글 작성, (2) 원글에 대한 댓글 개수 카운팅, (3) 사용자 활동 기록 추가가 모두 롤백되어야 합니다.이렇게 하나의 트랜잭션 안에서 여러 연산을 수행할 때 하나의 트랜잭션에 있는 연산들은 마치 하나의 연산인 것처럼 하나가 실패하면 모두 실패해서 롤백처리해야 하는 것을 트랜잭션의 원자성이라는 개념이라고 이야기합니다.","sql-transaction#SQL Transaction":"SQL 로도 Transaction 을 수행할 수 있습니다. 예를 들면 아래와 같이 START TRANSACTION 과 COMMIT 사이에 필요한 SQL을 작성해주면 됩니다.\nSTART TRANSACTION;\r\n\r\n// 필요한 연산들 작성\r\n\r\nCOMMIT;","transactiontemplate-transactional#TransactionTemplate, @Transactional":"스프링에서는 Transaction 을 처리할 때 전처리, 후처리(커밋, 롤백, 자원회수 등)코드로 인한 보일러 플레이트 코드들이 양산되지 않고 효과적으로 애플리케이션의 코드 들이 관리될 수 있도록 아래의 두가지 방식으로 트랜잭션 기능을 제공합니다.\nTransactionTemplate 에 람다 형태로 후처리를 위한 callback 메서드를 전달\n@Transactional 기반의 선언형 트랜잭션 처리 코드 사용","transactional#@Transactional":"사실 이번 문서 페이지에 @Transactional 을 정리할지말지 굉장히 고민했습니다. 기본적인 원칙들을 정리할 때 필요한 예제들도 많고 짧게 정리하고 넘어가면 또 뭔가 이상하기도 해서였습니다.고민을 거듭해본 결과 이번 문서에서는 가급적 간단한 내용들만을 다루기로 했습니다. MySQL 이라는 주제에서 벗어날 수도 있기 때문에 추후 별도의 jpa, querydsl 개념을 정리하는 카테고리를 정리할지 고민해봐야 할 것 같습니다.","스프링의-transactional-1#스프링의 @Transactional":"@Transactional 은 javax 에서 제공하는 @Transactional 도 있고 Spring 에서 제공하는 @Transactional 도 있습니다. 스프링의 @Transactional 은 javax 에서 제공하는 @Transactiaonl 에 비해 제공되는 기능이나 트랜잭션 전파 옵션 역시 다양하고 강력하게 제공되고 있기 때문에 가급적 스프링의 @Transactional 을 사용하는 것을 권장 드립니다.","transactional-메서드는-프록시-객체에서-실행#@Transactional 메서드는 프록시 객체에서 실행":"@Transactional 을 명시한 메서드는 스프링에 의해서 내부적으로는 해당 메서드가 속한 클래스를 상속받은(extends) 확장 클래스 객체를 프록시 객체가 실제로 Database 연산을 수행하고 Commit, Rollback, Resource 반납 등의 연산을 수행하게 됩니다.내부적으로는 Spring Data 에서 AOP 기반으로 @Transactional 이 붙은 메서드/클래스/인터페이스에 대한 처리를 하도록 되어 있습니다. 이런 동작으로 인해 간단하게 우리가 작성한 코드의 메서드 위에 @Transactional 을 붙이는 것 만으로 해당 메서드 내의 연산은 마치 하나의 연산인 것처럼 원자적 연산을 할 수 있게 됩니다.","transactional-사용-시-내부호출-상속관계에-유의#@Transactional 사용 시 내부호출, 상속관계에 유의":"@Transactional 이 적용된 메서드는 AOP 기반으로 동작하기 때문에 실제 객체를 상속(확장)받은 가짜 객체인 프록시객체를 기반으로 동작합니다. 따라서 해당 프록시의 메서드가 아닌 실제 객체의 메서드를 호출할 경우 @Transactional 이 적용되지 않는 이슈가 발생할 수 있습니다. @Transactional 연산의 원리를 이해하고 있지 못하거나 기억하고 있지 못한 경우 @Transactional 안에 많은 코드를 길게 늘여서 쓰는 안좋은 경우도 있습니다. @Transactional 이 언제 합류하고 언제 별도로 수행할 수 있도록 하는지는 트랜잭션 전파 옵션을 통해 해결이 가능합니다. 트랜잭션 전파 옵션에 관해서는 트랜잭션 전파옵션 문서를 참고해주세요. @Transactional 에 대한 기본 원칙은 아래와 같습니다.\n클래스레벨에 @Transactional\n클래스레벨에 @Transactional 이 적용되면 모든 public 메서드에 @Transactional 자동 적용\n@Transactional 덮어쓰기\n최 하위레벨에서 덮어쓴 선언이 최종 @Transactional 선언이 됩니다.\n인터페이스에 @Transactional\n인터페이스에도 @Transactional 이 적용될 수 있습니다.\n예외케이스) 같은 클래스 내 non-tx 메서드 → tx 메서드 호출하는 경우트랜잭션이 적용이 안되는 예외 케이스도 있습니다. 같은 클래스 내에 @Transactional 을 적용하지 않은 일반 메서드에서 @Transactional 이 적용된 메서드를 호출하는 경우, 프록시 객체에서 트랜잭셔널 메서드를 호출하는 것이 아니라 실제 객체에서 트랜잭셔널 메서드를 호출하게 되기에 트랜잭셔널이 적용되지 않습니다.요약해보면, Transactional 이 적용되지 않은 일반 메서드에서 같은 클래스내의 @Transactional 적용된 메서드를 객체 내에서 내부 호출하는 경우 트랜잭셔널 프록시를 거치지 못하게 됩니다. 즉, 이 경우에는 트랜잭셔널이 적용되지 않습니다.\ne.g.\n가짜 객체의 일반 메서드 A 호출 → 가짜객체는 실제 객체의 일반메서드 A 호출 →실제 객체의 일반 메서드A에서 @Transactional 메서드 AA 호출 → @Transactional 적용 안됨\n이것과 관련해서는 예전에 정리해둔 문서가 있고 원리를 설명해두긴 했던 문서인데 정말 너무 길어서 여기서 설명하기에는 무리입니다. 추후 별도의 카테고리를 추가해 정리해두도록 하겠습니다.@Transactional 이 적용된 메서드는 가급적 테스트 코드를 작성해서 실제로 하나의 트랜잭션안에서 수행됨을 보장하는지를 테스트하는 코드도 꼭 작성하는 것이 필요합니다.","exception-발생-시-스프링의-커밋롤백-정책#Exception 발생 시 스프링의 커밋/롤백 정책":"체크드, 언체크드 예외인지에 따라서 아래와 같이 커밋/롤백 여부가 달라집니다.\n언체크 예외(Unchecked Exception)\nRuntimeException (Java SE 9 & JDK 9 )\n스프링은 언체크 예외에 대해서 트랜잭션을 롤백합니다.\n언체크 예외는 복구 불가능한 예외로 여깁니다.\ne.g. RuntimeException, Error\n체크 예외(Checked Exception)\nException (Java Platform SE 8 )\n스프링은 체크 예외 발생시 트랜잭션을 롤백하지 않습니다.(커밋합니다.)\n복구가 가능한 예외로 간주하고 여기에 대한 처리 코드를 정의해주어야 합니다.\n체크 예외는 반드시 catch{...} 구문을 작성하기에 catch {...} 내에서 복구 로직을 정의해줍니다.\ne.g. 주문 시도 시 결제사 API 장애로 인해 실패시 주문은 성공시키고, 결제 대기 중으로 처리해야 할 경우\ne.g. Exception.class\n다만 체크 예외를 사용하더라도 @Transactional 에 rollbackFor 옵션에 원하는 예외 클래스를 지정하면, 예외가 발생하면 롤백을 합니다. (오버라이딩하는 느낌이라고 생각하시면 될 것 같습니다.)\n이러한 언체크 예외, 체크 예외는 아래와 같이 비즈니스 예외, 시스템 예외로 나누어서 기준을 마련해두는 것이 프로젝트 초기 작업 시에 혼선을 방지할 수 있어서 유리합니다.\n비즈니스 예외 (체크 예외)\n비즈니스 예외의 의미가 있을 때 사용\n체크예외로 취급\n비즈니스 적으로 예외가 발생한 것은 Checked 되어야 한다는 의미.\n비즈니스 적으로 예외가 발생하는 것은 어떤 상태에서 어떤 이유로 예외가 발생되었는지 기록이 되어야 하기에 예외가 발생하더라도 커밋이 되는 Checked Exception 을 사용합니다. (=체크를 한다는 의미)\ne.g. 예를 들어 환전 후 주식을 매수하는 로직이 있을 경우 환전 후 주식을 매수하려는 순간에 환율이 또 바뀌어서 잔고가 부족해서 주식 매수가 안될 때가 있습니다. 이런 경우 Checked Exception 을 통해서 명시적인 예외를 처리한 경우로 들 수 있습니다.\ne.g. 주문 후 결제 API 실패 시, 주문을 실패한 것이 아니라 결제 대기 중으로 처리해야 할 경우\n시스템 예외 (언체크 예외)\n복구할 수 없는 예외는 커밋이 되어야 하지 말아야 함.\n언체크드 예외로 취급합니다.\n예를 들면 네트워크 유실 등의 예외가 발생하면, 커밋이 발생하지 않도록 롤백 처리를 해주어야 합니다.","transactional-의-옵션들#@Transactional 의 옵션들":"","롤백#롤백":"스프링은 UncheckedException 발생시에 트랜잭션을 롤백합니다. CheckedException 발생시에는 롤백하지 않고 커밋합니다. 그런데 이런 원칙에 예외를 두는 것 또한 가능합니다. 바로 rollbackFor, noRollbackFor 옵션을 명시해서 특정 익셉션에 대해서 롤백을 하지 않도록 하거나 특정 익셉션에 대해서 롤백을 하도록 지정하는 것이 가능합니다.e.g. 체크드 익셉션이 롤백을 수행하도록 지정\n@Transactional(rollbackFor = Exception.class)\ne.g. 언체크드 익셉션이 롤백을 수행하지 않도록 지정\nMyHelloPrintException 은 RuntimeException 클래스를 상속받은 예외 클래스입니다. Runtime Exception 은 UncheckedException 이기에 예외 발생시 롤백을 하겠지만, 아래 코드에서 noRollbackFor 에 MyHelloPrintException 을 명시했으므로 MyHelloPrintException 이 발생했을 때 예외가 발생하지 않게 됩니다.\n@Transactional(noRallbackFor = MyHelloPrintException.class)","isolation#isolation":"트랜잭션 격리수준입니다. 실무에서 실제로 DBMS의 트랜잭션 격리수준을 수정할일은 크게 많지 않습니다.\nDEFAULT\n데이터베이스에서 설정하는 격리수준에 맞춰서 따라감\nDBMS에 설정된 기본 설정값 그대로 그냥 따라감\nREAD_UNCOMMITTED\nREAD_COMMITTED\nREPEATABLE_READ\nSERIALIZABLE","timeout#timeout":"트랜잭션 수행 시간에 대한 타임아웃을 지정합니다. 특정 시간 동안 트랜잭션에 지정한 작업이 완료되지 않으면 종료되도록 지정합니다. 운영환경에 따라 동작하는 경우도 있고 그렇지 않은 경우도 있기에 직접 확인 후에 사용하는 것이 필요합니다.","readonly#readOnly":"@Transactional 선언시 readOnly = true 를 주면 읽기 전용 트랜잭션 내에서 해당 메서드가 실행됩니다.readOnly =true 옵션은 드라이버나 데이터베이스에 따라 정상동작하지 않는 경우가 있습니다. 이 부분에 주의하시기 바랍니다. readOnly 옵션을 사용하면 읽기에서 라이브러리,JDBC드라이버, 데이터베이스 레벨에서 성능 최적화가 발생할 수 있습니다.예를 들어 JPA 와 같은 라이브러리에서는 읽기전용트랜잭션에서는 엔티티의 변경감지 기능을 수행하지 ㅇ낳기에 스냅샷 객체를 생성하지 않습니다. 읽기와 수정 작업시에 데이터 괴리가 염려되는 로직에서는 읽기 로직에 readOnly 를 사용하는 것도 좋은 방법입니다.","transactional-기반-테스트#@Transactional 기반 테스트":"","테스트코드-작성시-사용하는-transactional#테스트코드 작성시 사용하는 @Transactional":"테스트 코드에는 일반적으로 아래와 같이 @Transactional 을 적용해주는 편입니다.\n@Transactional\r\n@SpringBootTest\r\npublic class DoSomeTest{\r\n    // ... \r\n}\n테스트 수행시 테스트 클래스에 @Transactional 을 적용하면 해당 테스트에서 Database 에 적용된 사항은 묵시적으로 롤백됩니다. 이렇게 내부적으로 기본옵션으로 롤백되게끔 되어 있는 이유는 하나의 테스트에서 변경한 내용이 그대로 유지될 경우 다른 테스트 수행 시에 테스트에 영향을 줄 수 있기 때문입니다.","commint-rollback#@Commint, @Rollback":"권장되지는 않는 방법이지만, 필요할 경우도 있기에 정리해봅니다. @Transactional 을 명시했더라도 테스트 코드에서 롤백이 되지 않도록 하는 2가지 방법으로는 @Commit, @Rollback(value=false) 를 사용하는 경우를 예로 들 수 있습니다.@Transactional 을 테스트 메서드 또는 클래스에 설정했더라도 테스트 메서드에 @Commit 을 적용했을 경우에는 롤백이 수행되지 않고 커밋이 수행되게 됩니다. @Rollback(value = false) 를 메서드/클래스에 적용할 경우에도 테스트 종료 후 롤백 대신 커밋이 호출되게 됩니다.","테스트-코드-실행-시-database#테스트 코드 실행 시 Database":"","h2-memory-database#h2 memory Database":"인메모리 h2 Database 만으로도 테스트가 가능한 경우가 있습니다. 그런 경우라면 아래와 같이 설정해줍니다.\nspring.profiles.active=test\r\nspring.datasoruce.url=jdbc:h2:mem:db;DB_CLOSE_DELAY=1\r\nspring.datasource.username=sa","testcontainers#TestContainers":"하지만, JdbcTemplate 이나 MyBatis, Querydsl 을 이용해서 쿼리 최적화가 된 쿼리를 수행할 경우에는 MySQL, PostgreSQL, Oracle 과 같은 DBMS 에서 지원하는 SQL 이 H2 Database 의 일부 문법과 호환이 되지 않아서 h2 Database 에서 진행이 안되는 경우가 있습니다. 이런 경우 testcontainers 를 사용하면 됩니다. 옛날에는 Spring 에서 testcontainers 를 공식으로 채택하지 않아서 불편한점이 있었지만 최근에는 testcontainers 가 spring boot 에서 공식지원됩니다. TestContainers 는 Java 코드로도 생성할 수 있지만, docker-compose 기반의 mysql 도커 정의 파일을 만들어두고 이 docker-compose 파일 기반으로 테스트를 할 수 있도록 할수도 있습니다.이번 글에서는 글의 지면상 TestContainers 를 사용하는 방법에 대해서는 설명을 생략합니다.","트랜잭션-단위-테스트는-어떤식으로-하는지#트랜잭션 단위 테스트는 어떤식으로 하는지":"취업을 준비중이라 다른 문서도 정리해야하기에 바빠서 많은 내용을 쓰지는 못하지만 기본적인 내용만 적어보면 이렇습니다.","행위-기반-검증#행위 기반 검증":"when : @Transactional 이 적용된 메서드 내에서 Exception 이 발생하는 상황을 Mockito 를 이용해서 가정\nthen : @Transacitonal 이 적용된 해당 메서드 내에서 예외 발생 이후의 그 다음리안의 로직들이 실행되는지를 테스트 코드에서 Mockito.verify() 를 통해 호출여부를 검증\n여기까지는 실행되어야 하고\n여기까지는 실행이 되지 말아야 한다","결과-기반-검증#결과 기반 검증":"given : @Transactional 이 적용된 메서드 수행 전에 특정 데이터가 저장된 상황을 가정해서 데이터를 저장\nwhen : @Transactional 이 적용된 메서드 내에서 Exception 이 발생하는 상황을 Mockito 를 이용해서 가정\nthen : @Transacitonal 이 적용된 해당 메서드의 예외 발생 이후에 대해 테스트 코드에서 Assertion 을 통해서 특정값이 원하는 값이 되는지 검증\n행위 기반 검증의 경우 내부 메서드의 로직이 변화하면 테스트 메서드가 깨질 경우도 있다는 점을 유념하고 계셔야 합니다.이 외에도 여러가지 방법이 있을 수 있습니다. 제가 생각해냈던 트랜잭션 단위의 롤백, 커밋을 검증하는 방법들은 위의 두 방법인데요. 이 방법들 외에도 여러 방법들이 있지 않을까 싶습니다. 위의 방법이 정해진 방법은 아닙니다. 실무에서는 꼭 직접 생각해서 관련 코드의 상황에 따라 다른 테스트 코드를 직접 생각해서 만들어내야 합니다."}},"/transaction/transactional-propagation-option":{"title":"Transactional Propagation Option","data":{"트랜잭션-전파-옵션#트랜잭션 전파 옵션":"트랜잭션 전파 옵션은 여러가지가 있습니다. 그 중 가장 많이 쓰이는 것는 REQUIRED, REQUIRED_NEW 입니다. 이 외에도 여러가지 전파 옵션이 있는데, 특수한 케이스에 대해 대응 방안이 될수 있도록 하기 위해 여러가지 트랜잭션 전파옵션들을 간략하게 정리해봅니다.","required#REQUIRED":"가장 많이 사용하는 기본설정입니다. 기존 트랜잭션이 없으면 생성하고 있으면 기존 트랜잭션에 참여합니다.\n기존 트랜잭션 없음 : 새로운 트랜잭션을 생성합니다.\n기존 트랜잭션 있음 : 기존 트랜잭션에 참여합니다.","required_new#REQUIRED_NEW":"기존 트랜잭션에서 파생되었더라도, 또는 합류할 기존 트랜잭션이 있더라도 항상 새로운 트랜잭션을 생성합니다.\n기존 트랜잭션 없음 : 새로운 트랜잭션을 생성합니다.\n기존 트랜잭션 있음 : 새로운 트랜잭션을 생성합니다.\nREQUIRED_NEW 를 사용할 때에는 새로운 트랜잭션에 참여 했음에 유의해서 봐야 합니다. (같은 트랜잭션으로 처리되지 않고 개별 트랜잭션으로 처리됩니다.)","support#SUPPORT":"트랜잭션을 지원한다는 의미입니다. 기존 트랜잭션이 없으면 없는 대로 진행하고 기존 트랜잭션이 있으면 참여합니다.\n기존 트랜잭션 없음 : 트랜잭션 없이 진행합니다.\n기존 트랜잭션 있음 : 기존 트랜잭션에 참여합니다.","not_support#NOT_SUPPORT":"트랜잭션을 지원하지 않는다는 의미입니다.\n기존 트랜잭션 없음 : 트랜잭션 없이 진행합니다.\n기존 트랜잭션 있음 : 트랜잭션 없이 진행합니다.(이미 있는 기존 트랜잭션은 보류합니다).","mandatory#MANDATORY":"의무사항입니다. 트랜잭션이 반드시 있어야 합니다. 기존 트랜잭션이 없으면 예외가 발생합니다.\n기존 트랜잭션 없음 : IllegalTransactionStateException 예외가 발생합니다.\n기존 트랜잭션 있음 : 기존 트랜잭션에 참여합니다.","never#NEVER":"트랜잭션을 사용하지 않는다는 의미입니다. 기존 트랜잭션이 있으면 예외가 발생합니다. 기존 트랜잭션도 허용하지 않는 강한 부정의 의미로 이해하면 됩니다.\n기존 트랜잭션 없음 : 트랜잭션 없이 진행합니다.\n기존 트랜잭션 있음 : IllegalTransactionStateException 예외가 발생합니다.","nested#NESTED":"중첩 트랜잭션은 외부 트랜잭션의 영향을 받지만, 중첩 트랜잭션은 외부에 영향을 주지 않습니다.\n기존 트랜잭션 없음 : 새로운 트랜잭션을 생성합니다.\n기존 트랜잭션 있음 : 중첩 트랜잭션을 생성합니다.\n기존 트랜잭션이 실패하면, 내부에서 생성된 중첩 트랜잭션도 함께 실패합니다. 내부에서 생성된 트랜잭션이 실패하면, 기존 트랜잭션은 아무 영향을 받지 않습니다."}},"/transaction/what-is-acid":{"title":"What Is Acid","data":{"트랜잭션의-기본-4-원칙-acid#트랜잭션의 기본 4 원칙 (ACID)":"ACID 는 ANSI 에서 트랜잭션이 갖춰야 할 4가지 성격을 의미하며 아래의 4 단어의 앞글자를 따서 ACID 라고 부릅니다.\nAtomicity (원자성)\n트랜잭션 하나는 하나의 원자적인 단위로 취급되어야 하며, 하나의 트랜잭션 내에서 연산 하나가 실패할 경우 트랜잭션 내부의 모든 연산이 롤백되어야 합니다.\nConsistency (일관성)\n트랜잭션에서 수행하는 연산은 데이터베이스의 무결성 제약 조건이 지켜져야 합니다.\nIsolation (격리성)\n수행중인 트랜잭션은 다른 트랜잭션에 의해 변경되거나 수정되지 않아야 합니다.\n트랜잭션의 4가지 원칙 중 가장 기술적으로 난이도가 높은 원칙이 격리성입니다. ANSI 에서는 네가지 수준의 격리수준을 정의하고 있습니다. 트랜잭션 격리수준에 대해서는 다음 문서에서 자세히 정리할 예정입니다.\nDurability (지속성)\n완료된 트랜잭션은 기록되어야 합니다.\n트랜잭션이 성공했어도 시스템 문제가 발생할 경우, 데이터베이스 로그 등을 이용해 성공한 트랜잭션 내용을 복구할 수 있어야 합니다."}},"/transaction/what-is-mvcc":{"title":"What Is Mvcc","data":{"mvcc-multi-version-concurrency-control#MVCC (Multi Version Concurrency Control)":"MVCC (Multi Version Concurrency Control) 는 \"다중 버전 동시성 제어\"라고 불립니다.\nMVCC 를 알아보기 전에 먼저 \"동시성제어 (Concurrency Control)\"를 먼저 알아보고, MVCC 는 무엇인지 알아봅니다.","동시성-제어-concurrency-control#동시성 제어 (Concurrency Control)":"주로 트랜잭션의 격리성을 확보하기 위해 동시성 제어가 필요합니다. DBMS 에 다수의 사용자로부터 동시에 트랜잭션이 발생할 때 트랜잭션 사이에 상호간섭이 발생할 수 있는 상황이 발생하는데 이런 상황에 대해 Database 를 보호하는 것을 의미합니다. 동시성을 낮추면 데이터의 일관성이 낮아져서 서로 다른 트랜잭션에서 바라보는 데이터가 다를 경우가 있습니다. 반면 동시성을 높이면 데이터의 일관성은 높아집니다.","동시성-제어의-종류-pessimistic-optimistic#동시성 제어의 종류 (Pessimistic, Optimistic)":"동시성 제어를 위해서는 낙관적 락, 비관적 락을 사용합니다. 낙관적 락의 경우 애플리케이션 레벨에서 시간, 버전 등을 기록해서 이것을 통해서 충돌 여부를 감지하고 변경 여부를 롤백하는 것을 의미합니다. 낙관적 락은 데이터의 버전별로 독자적으로 트랜잭션을 수행할 수 있기 때문에 동시성이 높습니다. 하지만 충돌시 롤백 처리를 직접 구현해야 하고, 충돌 처리 시에 데이터를 불러오거나 하는 등의 작업을 해야 하기에 연산 비용이 크기도 합니다.비관적 락의 경우 데이터베이스에서 제공하는 SELECT FOR UPDATE, SELECT FOR SHARE 와 같은 SQL 을 사용하는 것을 의미합니다. 락을 배타적으로 걸어서 락을 걸기로 선택한 자원에 대한 접근이 제한되게 됩니다. 데이터의 일관성을 높은 수준으로 제공할 수 있고 격리수준을 높여서 다른 트랜잭션의 접근을 방어할 수 있다는 점은 좋습니다. 하지만 배타적으로 락을 걸기 때문에 동시성 성능이 급감하게 되고 데드락이 발생할 확률이 높은 편이기에 대규모 트래픽에서 사용하기에는 적절하지 않습니다.낙관적 락, 비관적 락에 대해 쉬운 자료를 찾고 싶으시다면 낙관적 락과 비관적 락 을 참고해주시기 바랍니다.","mvcc-multi-version-concurrency-control-1#MVCC (Multi Version Concurrency Control)":"트랜잭션의 격리 수준을 보장하기 위해 비관적락, 낙관적 락을 사용해서 동시성 제어를 할 수도 있지만, 상용 DBMS들은 락을 사용하지 않고도 동시성을 제공 가능하도록 다중버전 동시성 제어 (MVCC (Multi Version Concurrency Control)) 기능을 제공합니다.MySQL 의 경우 Undo Segment 방식을 통해 MVCC 기능을 제공하고, PostgreSQL의 경우 MGA 방식을 통해 MVCC 기능을 제공합니다.\nUndo Segment 방식\n최신 데이터는 기존 데이터 블록의 레코드에 반영한다.\n변경 전의 값은 undo 영역이라는 별도의 공간에 저장하고, 갱신에 대한 버전관리를 한다.\n자세한 내용은 우아한 형제들 기술블로그 - Aurora MySQL vs Aurora PostgreSQL 을 참고해주시기 바랍니다.\nMGA 방식\n튜플을 Update 할 때 새로운 값으로 replace 하지 않고 이전 튜플은 유효범위를 마킹해서 처리하는 방식\nMGA 방식은 트리 구조를 이용하는데, 짧은 시간 내에 같은 행을 수정하는 단발성 업데이트 작업의 빈도가 많다면 당연히 MVCC 로 인해 데드 트리가 많이 생기는데, 이 양이 많아지면 N^M 과 같은 어마 어마한 양의 디스크 사용량이 발생할 수 있다는 사실을 기억해두어야 합니다.\n따라서 PostgreSQL 은 Insert/Select 위주의 서비스라면 적합하겠지만, Update 가 많은 시스템에는 MVCC 로 인해 운영상에 이슈가 자주 발생할 소지가 있습니다. 예를 들어 증권데이터처럼 주식에 대한 현재가격이 계속해서 변해야 하는 시스템에는 MVCC 로 인해 발생하는 데드 튜플들을 청소해줘야 하므로 주기적으로 Vaccum 을 수행해줘야 하고, 쓰지 않는 디스크 공간의 파편화가 자주 발생하는 등 부적합한 요소들이 많습니다.\n자세한 내용은 PostgreSQL MVCC/SQL 을 참고해주시기 바랍니다.","dbms-별-트랜잭션-격리-수준#DBMS 별 트랜잭션 격리 수준":"DBMS별로 기본으로 설정된 트랜잭션 격리수준은 아래와 같습니다.\nMySQL (InnoDB 스토리지 엔진을 사용할 경우)\nRepeatable Read\nOracle\nRead Committed\nPostgresql\nRead Committed\n대부분의 Database는 Read Committed 이상의 레벨을 기본 격리수준으로 채택하고 있습니다."}},"/uuid-vs-auto-increment":{"title":"Uuid Vs Auto Increment","data":{"uuid-vs-auto-increment#UUID vs Auto Increment":"정리 예정.\nUUID vs Auto Increment 중 PK 선택하기\nUUID 와 increment PK 는 언제 사용해야할까?\n엔티티의 id 를 AUTO_INCREMENT 가 아닌 UUID 를 사용하고자 할 때는"}},"/when-you-choose-dbms/sometimes-nosql-is-better-choice":{"title":"Sometimes Nosql Is Better Choice","data":{"nosql이-더-좋은-선택일-경우-feat-subset-패턴#NoSQL이 더 좋은 선택일 경우 (feat. Subset 패턴)":""}},"/when-you-choose-dbms/when-you-choose-mysql-postgresql":{"title":"When You Choose Mysql Postgresql","data":{"mysql-postgresql-선택시-고려해볼-것들#MySQL, PostgreSQL 선택시 고려해볼 것들":"개인적으로 느끼기에는 PostgreSQL 은 관리성 측면의 소형 DB이거나 어드민 DB, 고난이도 쿼리를 위한 정산 용도의 별도 DBMS 인 경우에 사용하기에 유리한 측면이 있는 것 같고, MySQL 의 경우 트래픽이 다소 발생하는 B2C 계열에 적합하다는 느낌입니다.","참고#참고":"우아한 형제들 기술블로그 - Aurora MySQL vs Aurora PostgreSQL\nMySQL vs PostgreSQL 비교\nOracle, MySQL, PostgreSQL 차이점은?","rdbms-ordbms#RDBMS, ORDBMS":"PostgreSQL 은 객체 관계형 DB다. (ORDBMS)\n테이블 상속기능이 제공된다. 자식 테이블은 부모테이블로부터 컬럼을 상속받아 사용가능하다.\n기본적으로는 관계형 데이터베이스지만, 객체 데이터베이스와 연관되는 기능(테이블 상속/함수 오버로딩) 역시 포함하고 있다.","멀티스레드-vs-멀티프로세스#멀티스레드 vs 멀티프로세스":"PostgreSQL 은 멀티 프로세스 방식이다.\nMySQL 은 멀티 스레드 방식이다.","postgresql-의-단순-crud-성능--복잡한-쿼리-#PostgreSQL 의 단순 CRUD 성능 ↓ 복잡한 쿼리 ↑":"PostgreSQL은 단순 CRUD시에 MySQL에 비해서 성능이 떨어진다.\nPostgreSQL 은 복잡한 쿼리를 요구하거나 대규모 서비스에 특화되어 있다.","mvcc-지원방식#MVCC 지원방식":"MySQL\nUndo Segment 방식\n최신 데이터는 기존 데이터 블록의 레코드에 반영한다.\n변경 전의 값은 undo 영역이라는 별도의 공간에 저장하고, 갱신에 대한 버전관리를 한다.\nPostgreSQL\nMGA 방식\n튜플을 Update 할 때 새로운 값으로 replce 하지 않고 이전 튜플은 유효범위를 마킹해서 처리하는 방식","update-방식--postgresql-은-insertselect-위주의-서비스에-적합#Update 방식 : PostgreSQL 은 Insert/Select 위주의 서비스에 적합":"MySQL 은 Update 를 그대로 수행한다.PostgreSQL 은 Insert & Delete (삭제표시) 를 수행한다.\nPostgreSQL 은 UPDATE 시 내부적으로는 새 행이 INSERT 되고 이전 데이터는 삭제 표시된다.\n모든 인덱스에는 보통 행의 실제 위치값에 대한 링크가 표기된다. 따라서 행이 업데이트 되면 변경된 위치값 (새로 추가된 행)에 대한 인덱스 정보도 업데이트가 필요하다. 이런 과정 때문에 UPDATE 시에는 MySQL 보다 성능이 떨어지게 된다.\nPostgreSQL 은 Update 시 변경 전 값을 삭제 마크 처리한 후 새로운 행을 INSERT 한다. 새롭게 INSERT 된 값이 변경 후의 값이 된다.이런 이유로 PostgreSQL은 보통 Insert, Select 위주의 서비스에 사용되는 것이 선호된다.","지원되는-join#지원되는 JOIN":"MySQL 은 NL JOIN, HASH JOIN 을 지원한다.PostgreSQL 은 NL JOIN, HASH JOIN, SORT JOIN 을 지원한다.","parallel-query-for-select#Parallel Query for SELECT":"MySQL 5.7.2.09.2 버전부터 지원되기 시작했다.PostgreSQL 9.6 버전부터 지원되기 시작했다.\nPostgreSQL 은 오래 전부터(9버전) 대부분의 SELECT 쿼리에서 parallel 기능이 지원되고 있다.","테이블-기본-구성-인덱스#테이블 기본 구성 인덱스":"MySQL 은 기본키에 대해 Clustered Index를 지원한다.ㅍPostgreSQL 은 기본키에 대해 Non Clustered Index 가 적용된다.","성능비교#성능비교":"","postgresql-의-partial-index#PostgreSQL 의 Partial Index":"PostgreSQL 에는 전체데이터의 부분 집합에 대해서만 인덱스를 생성하는 Partial Index 라는 기능이 있다.특정 범위에 대해서만 인덱싱을 하는 기능이다.대량 데이터의 일부 값/범위에 대해 인덱스를 생성할 경우 인덱스 크기도 작고 관리하는 리소스도 줄일 수 있다는 장점이 있다.조회 시에는 PostgreSQL의 성능과 MySQL의 조회성능이 큰 차이를 보여주지 않았다고 한다.인덱스 크기를 확인해보면, PostgreSQL 의 크기가 10배정도 더 작다. 필요한 부분만 인덱스를 생성하기 때문에 저장공간에 대한 이점이 크며, 데이터 삭제,추가,갱신에 따른 인덱스 유지관리 비용도 절약된다.","secondary-index-생성#Secondary Index 생성":"참고) online ddl 은 꽤 부담스러운 작업에 속한다.테이블에 이미 저장되어 있는 데이터가 많기에 시간소요 예측이 힘들고, 작업이 실패한다면 rollback 작업에 따른 위험도도 크다.\n시간예측을 할때는 보통 백업 데이터로 테스트를 진행하지만, 라이브 환경에서는 시간 소요가 더 오래 걸리는 경우가 많다.\n이미 존재하는 테이블에 인덱스,컬럼 추가작업 시의 성능 실험Aurora MySQL\n100G 테이블의 인덱스, 컬럼 추가를 하는 데에 1시간이 넘는 시간이 소요된다.\n100G 만 넘어도 인댁스/컬럼 추가시 1시간이 넘게 소요된다.\nAurora PostgreSQL\n200G 테이블의 인덱스,컬럼 추가를 하는 데에 40분 만에 인덱스 추가가 완료되고 컬럼 추가는 바로 된다.\nPostgreSQL 의 online DDL 컬럼 추가는 시스템 카탈로그에 추가될 정보만 반영하므로 꽤 빠른 작업이 가능하다.\n시스템 카탈로그는 meta data 를 저장하는 역할을 수행한다.","그-밖의-postgresql-특징들#그 밖의 PostgreSQL 특징들":"SP\nVaccum\nPostGIS\nMaterialized View\n상속기능\npg_trgm","sp#SP":"c/c++, Java, Javascript, .Net, R, Perl, Python, Ruby, Tcl 등으로 PostgreSQL 에 SP 생성이 가능하다.","postgis#PostGIS":"geographic object를 지원 가능하다. oracle의 GIS 와 성능이 비견할 정도로 뛰어나다.","vaccum#Vaccum":"PostgreSQL 은 MVCC 를 MGA 방식으로 구현한다.그래서 UPDATE , DELETE시에 물리적으로 공간을 UPDATE하여 사용하지 않고 새로운 영역을 할당하여 사용하게 된다.즉 이전 공간이 재사용 될 수 없는 dead tuple 상태로 저장공간을 두게 되어서 이러한 현상이 지속될 경우, 공간 부족 및 데이터IO의 비효율을 유발하여 성능저하의 원인이 된다.따라서, 주기적으로 vacuum 기능을 수행하여 재사용 가능하도록 관리해 주어야 한다.","materialized-view-지원#Materialized View 지원":"일반 View 와는 다르게 snapshot이라고 불리는 Materialized View는 view 생성 시 설정한 조건의 쿼리 결과를 별도의 공간에 저장하고 쿼리가 실행될 때 미리 저장된 결과를 보여주어 성능을 향상시킨다.실시간 노출 필요성이 적은 통계성 쿼리나, 자주 update 되지 않는 테이블에 생성할 때 성능효과를 볼 수 있다.","상속-기능#상속 기능":"부모테이블을 생성 후 상속기능을 이용해 하위 테이블을 만들 수 있다.\n하위 테이블은 상속받은 부모테이블의 컬럼을 제외한 컬럼만 추가로 생성하면 된다.\n상위 테이블에서 조회 시 기본적으로 하위 테이블의 데이터까지 모두 조회 가능하다.\n데이터 변경 시에도 하위 테이블까지 모두 반영된다.","다양한-사용자-기반-활용-가능#다양한 사용자 기반 활용 가능":"연산자, 복합 자료형, 집계함수, 자료형 변환자, 확장 기능 등 다양한 데이터베이스 객체를 사용자가 임의로 만들 수 있는 기능을 제공한다.","pg_trgm#pg_trgm":"trigram매칭을 기반으로 한 모듈로 데이터 간 유사성 파악 및 like %pattern%(3자이상) 인덱스 검색이 가능하다.","postgresql-을-사용하면-좋은-경우-및-단점들#PostgreSQL 을 사용하면 좋은 경우 및 단점들":"(부가적으로 조금 더 참고한자료 : Oracle, MySQL, PostgreSQL 차이점)\n테이블 상속 기능등을 활용하고 싶은 경우\n확장성, 호환성이 필요한 경우 PostgreSQL 이 필요하다.\nMaterialized View, pg_trgm, Sort Join 등과 같은 검색에 유용한 기능을 사용하고자 할 때\nPostGIS 를 지원한다.\nInsert/Select 위주의 서비스에 적합\n(Update가 잦은 경우는 PostgreSQL 에서는 성능이 불안정)\n새로운 행을 insert 한 후에 과거의 행은 delete 마크를 붙이기에 update가 잦으면 계속해서 과거의 행의 양이 계속 늘어난다. 이것을 dead tuple 이라고 부른다. 이런 현상으로 인해 Vaccum 을 주기적으로 수행해줘야 한다.\n다양한 join 방법을 제공한다.\nnested loop join, hash join, sort merge join\n결합할 데이터가 많을 경우는 Hash Join, Merge Join 을 사용한다.\n데이터가 이미 정렬되어 있는 경우 Sort Merge 를 사용\n데이터가 정렬되어 있지 않다면 Hash Join 이 권장된다.\n부가적인 장점\n컬럼 추가 등과 같은 online ddl 사용시 MySQL에 비해 월등히 성능이 우월하다.\n데이터베이스 클러스터 백업 기능을 제공한다.\n클러스터 : 디스크로부터 데이터를 읽어오는 시간을 줄이기 위해 자주 사용되는 테이블의 데이터를 디스크의 가까운 위치에 저장시키는 방법\n단점 역시 있다.\nupdate를 할 때, 과거 행을 삭제된 표시를 하고 변경된 데이터를 가진 새로운 행을 추가하는 형태라서 update가 느리다.\n처리 속도를 빠르게 하기 위해 여러 CPU를 활용하여 쿼리를 실행한다.\n설정이 복잡하다. 광범위한 기능들과 표준 SQL에 대한 강력한 준수로 인해 PostgreSQL은 간단한 데이터베이스 설정에 대해서도 많은 설정이 필요하다.\n속도가 중요하고 읽기 작업이 많으면 MySQL 이 더 실용적인 선택이 될 수 있다.\n단순한 레플리케이션 작업에는 적합하지 않다.\nPostgreSQL에서도 레플리케이션을 잘 제공하고 있지만 여전히 비교적 새로운 기능이다.\n레플리케이션은 MySQL 에서 더 성숙한 기능이고 많은 사용자들이 필요한 데이터베이스 및 시스템 관리 경험이 부족한 사용자들은 MySQL 의 레플리케이션 기능을 구현하는 것이 더 쉽다.","postgresql-에-비해-mysql-을-고려해야-하는-경우#PostgreSQL 에 비해 MySQL 을 고려해야 하는 경우":"Update 가 잦은 경우\nMVCC 수행시 Update 가 잦은 경우 dead tuple 들이 자주 발생하는 이유로 Database 머신 내에서 Disk Full 등과 같은 이슈가 자주 발생한다. 따라서 PostgreSQL을 사용할 때 Vaccum을 자주 수행해줘야 한다는 단점이 있다.\n멀티 스레드 기반의 Database 엔진을 사용하고자 할때\nMySQL 은 멀티스레드 기반의 엔진이다.","mysql-의-장단점#MySQL 의 장단점":"오픈소스로 무료로 사용가능하다.\ntop n개의 레코드를 가지고 오는 케이스에 특화되어 있다.\nupdate 성능이 postgre보다 우수하다.\nNested Loop Join만 지원한다.\n복잡한 알고리즘은 가급적 지원하지 않는다.\n문자열 비교에서 대소 문자를 구분하지 않는다.\n간단한 처리 속도를 향상 시키는 것을 추구함\n간단한 데이터 트랜잭션을 위한 데이터베이스가 필요한 웹 기반 프로젝트에 널리 사용된다. 로드가 많거나 복잡한 쿼리는 성능이 저하된다.\nNested Loop Join 바깥 테이블의 처리 범위를 하나씩 접근하면서 추출된 값으로 안쪽 테이블을 조인하는 방식이다.\n중첩 루프문과 동일한 원리\n좁은 범위에 유리하다.\n순차적으로 처리한다."}}}